{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "474e2506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 21:14:46.154928: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-09 21:14:47.420268: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-03-09 21:14:47.420476: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-03-09 21:14:47.420495: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n",
      "0.31.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import tensorflow_io as tfio\n",
    "print(tfio.__version__)\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7e98905",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/tfrecords\"\n",
    "\n",
    "\n",
    "def natural_keys(text):\n",
    "    \"\"\n",
    "    def atoi(text):\n",
    "        return int(text) if text.isdigit() else text\n",
    "    \n",
    "    return [atoi(c) for c in re.split(r'(\\d+)', text)]\n",
    "\n",
    "tfrecords = sorted(glob(f\"{data_path}/*.tfrec\"), key=natural_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2e73abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "train_tfrecords, valid_tfrecords = tfrecords[:19], tfrecords[19:]\n",
    "print(len(train_tfrecords)+len(valid_tfrecords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4be53dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sequence(serialized_sequence):\n",
    "    return tf.io.parse_tensor(\n",
    "        serialized_sequence,\n",
    "        out_type=tf.float32,\n",
    "    )\n",
    "\n",
    "\n",
    "def parse_tfrecord_fn(example):\n",
    "    feature_description = {\n",
    "        \"n_frames\": tf.io.FixedLenFeature([], tf.float32),\n",
    "        \"frames\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    \n",
    "    return tf.io.parse_single_example(example, feature_description)\n",
    "\n",
    "\n",
    "NUM_FRAMES = 16\n",
    "\n",
    "def true_fn(frames, n_frames):\n",
    "    num_left_frames = NUM_FRAMES - n_frames\n",
    "    left_frames = tf.zeros(shape=(num_left_frames, 543, 3))\n",
    "    frames = tf.concat([frames, left_frames], 0)\n",
    "\n",
    "    return frames\n",
    "\n",
    "\n",
    "def false_fn(frames):\n",
    "    frames = tf.slice(\n",
    "        frames,\n",
    "        begin=[0,0,0],\n",
    "        size=[NUM_FRAMES, 543, 3]\n",
    "    )\n",
    "    \n",
    "    return frames\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def preprocess_frames(frames, n_frames):\n",
    "    \"\"\"This is where different preprocessing logics will be experimented.\"\"\"\n",
    "    # nan to num\n",
    "    frames = tf.where(tf.math.is_nan(frames), 0.0, frames)\n",
    "    \n",
    "    # sample frames\n",
    "    frames = tf.cond(\n",
    "        tf.less(n_frames, NUM_FRAMES),\n",
    "        true_fn = lambda: true_fn(frames, n_frames),\n",
    "        false_fn = lambda: false_fn(frames),\n",
    "    )\n",
    "    \n",
    "    return frames\n",
    "\n",
    "\n",
    "def parse_data(example):\n",
    "    # Parse Frames\n",
    "    n_frames = example[\"n_frames\"]\n",
    "    frames = tf.reshape(parse_sequence(example[\"frames\"]), shape=(n_frames, 543, 3))\n",
    "    frames = preprocess_frames(frames, n_frames)\n",
    "    \n",
    "    # Parse Labels\n",
    "    label = tf.one_hot(example[\"label\"], depth=250)\n",
    "\n",
    "    return frames, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9977685",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 21:14:56.422156: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 21:14:56.616676: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 21:14:56.617133: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 21:14:56.622000: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-09 21:14:56.624894: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 21:14:56.625292: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 21:14:56.625659: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 21:14:58.910164: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 21:14:58.911682: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 21:14:58.912085: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 21:14:58.913368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15389 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = tf.data.TFRecordDataset(train_tfrecords)\n",
    "valid_ds = tf.data.TFRecordDataset(valid_tfrecords)\n",
    "\n",
    "train_ds = (\n",
    "    train_ds\n",
    "    .map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n",
    "    .shuffle(1024)\n",
    "    .map(parse_data, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(128)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "valid_ds = (\n",
    "    valid_ds\n",
    "    .map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n",
    "    .map(parse_data, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(128)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "654f86c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 16, 543, 3)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 16, 468, 3)  0           ['input_1[0][0]']                \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " conv_lstm1d (ConvLSTM1D)       (None, 461, 32)      35968       ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 454, 32)      8224        ['conv_lstm1d[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 16, 21, 3)   0           ['input_1[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3 (Sl  (None, 16, 21, 3)   0           ['input_1[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2 (Sl  (None, 16, 33, 3)   0           ['input_1[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 227, 32)      0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_lstm1d_1 (ConvLSTM1D)     (None, 14, 32)       35968       ['tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv_lstm1d_2 (ConvLSTM1D)     (None, 14, 32)       35968       ['tf.__operators__.getitem_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv_lstm1d_3 (ConvLSTM1D)     (None, 26, 32)       35968       ['tf.__operators__.getitem_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 220, 64)      16448       ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 7, 64)        16448       ['conv_lstm1d_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 7, 64)        16448       ['conv_lstm1d_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 19, 64)       16448       ['conv_lstm1d_3[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 110, 64)     0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 3, 64)       0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 3, 64)       0           ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 9, 64)       0           ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 110, 64)      0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 3, 64)        0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 3, 64)        0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 9, 64)        0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 125, 64)      0           ['dropout[0][0]',                \n",
      "                                                                  'dropout_1[0][0]',              \n",
      "                                                                  'dropout_2[0][0]',              \n",
      "                                                                  'dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 8000)         0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 250)          2000250     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,218,138\n",
      "Trainable params: 2,218,138\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# def get_model():\n",
    "#     inputs = layers.Input((32, 543, 3))\n",
    "#     x = layers.ConvLSTM1D(16, 2)(inputs)\n",
    "#     x = layers.GlobalAveragePooling1D()(x)\n",
    "#     x = layers.Dropout(0.5)(x)\n",
    "#     x = layers.Dense(250, activation=\"softmax\")(x)\n",
    "    \n",
    "#     return models.Model(inputs, x)\n",
    "\n",
    "\n",
    "def conv1d_lstm_block(inputs, filters):\n",
    "    vector = tf.keras.layers.ConvLSTM1D(filters=32, kernel_size=8)(inputs)\n",
    "    for f in filters:\n",
    "        vector = tf.keras.layers.Conv1D(filters=f, kernel_size=8)(vector)\n",
    "        vector = tf.keras.layers.MaxPooling1D()(vector)\n",
    "    vector = tf.keras.layers.Dropout(0.3)(vector)\n",
    "    return vector\n",
    "\n",
    "def get_model():\n",
    "    inputs = tf.keras.Input((NUM_FRAMES, 543, 3), dtype=tf.float32)\n",
    "\n",
    "    # Features\n",
    "    face_inputs = inputs[:, :, 0:468, :]\n",
    "    left_hand_inputs = inputs[:, :, 468:489, :]\n",
    "    pose_inputs = inputs[:, :, 489:522, :]\n",
    "    right_hand_inputs = inputs[:, :,522:,:]\n",
    "\n",
    "    face_vector = conv1d_lstm_block(face_inputs, [32, 64])\n",
    "    left_hand_vector = conv1d_lstm_block(left_hand_inputs, [64])\n",
    "    right_hand_vector = conv1d_lstm_block(right_hand_inputs, [64])\n",
    "    pose_vector = conv1d_lstm_block(pose_inputs, [64])\n",
    "    \n",
    "    vector = tf.keras.layers.Concatenate(axis=1)([face_vector, left_hand_vector, right_hand_vector, pose_vector])\n",
    "    vector = tf.keras.layers.Flatten()(vector)\n",
    "    output = tf.keras.layers.Dense(250, activation=\"softmax\")(vector)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "689d3ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    \"adam\",\n",
    "    \"binary_crossentropy\",\n",
    "    metrics=[\"acc\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "006e4b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "585/585 [==============================] - 211s 337ms/step - loss: 0.0301 - acc: 0.0059 - val_loss: 0.0250 - val_acc: 0.0248\n",
      "Epoch 2/10\n",
      "585/585 [==============================] - 183s 313ms/step - loss: 0.0235 - acc: 0.0449 - val_loss: 0.0216 - val_acc: 0.0952\n",
      "Epoch 3/10\n",
      "585/585 [==============================] - 182s 311ms/step - loss: 0.0209 - acc: 0.1206 - val_loss: 0.0194 - val_acc: 0.1843\n",
      "Epoch 4/10\n",
      "585/585 [==============================] - 183s 312ms/step - loss: 0.0190 - acc: 0.1978 - val_loss: 0.0181 - val_acc: 0.2439\n",
      "Epoch 5/10\n",
      "585/585 [==============================] - 182s 310ms/step - loss: 0.0178 - acc: 0.2544 - val_loss: 0.0171 - val_acc: 0.2846\n",
      "Epoch 6/10\n",
      "585/585 [==============================] - 181s 310ms/step - loss: 0.0170 - acc: 0.2915 - val_loss: 0.0175 - val_acc: 0.2739\n",
      "Epoch 7/10\n",
      "585/585 [==============================] - 181s 310ms/step - loss: 0.0164 - acc: 0.3195 - val_loss: 0.0173 - val_acc: 0.2855\n",
      "Epoch 8/10\n",
      "585/585 [==============================] - 182s 311ms/step - loss: 0.0159 - acc: 0.3431 - val_loss: 0.0160 - val_acc: 0.3412\n",
      "Epoch 9/10\n",
      "585/585 [==============================] - 181s 309ms/step - loss: 0.0155 - acc: 0.3664 - val_loss: 0.0162 - val_acc: 0.3412\n",
      "Epoch 10/10\n",
      "585/585 [==============================] - 181s 310ms/step - loss: 0.0151 - acc: 0.3860 - val_loss: 0.0159 - val_acc: 0.3494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fde0c11a390>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=valid_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f368d0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154/154 [==============================] - 10s 66ms/step - loss: 0.0159 - acc: 0.3494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.015903348103165627, 0.3493902385234833]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e192c5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: baseline/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: baseline/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"models/baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d3e2da",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f1542b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROWS_PER_FRAME = 543  # number of landmarks per frame\n",
    "SAMPLE_FILE = \"train_landmark_files/2044/635217.parquet\"\n",
    "\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)\n",
    "\n",
    "frames = load_relevant_data_subset(SAMPLE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b9977e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 543, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45a58184",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessing(tf.Module):\n",
    "    def __init__(self, num_frames=NUM_FRAMES, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.num_frames = num_frames\n",
    "        \n",
    "    def true_fn(self, frames, n_frames):\n",
    "        num_left_frames = self.num_frames - n_frames\n",
    "        left_frames = tf.zeros(shape=(num_left_frames, 543, 3))\n",
    "        frames = tf.concat([frames, left_frames], 0)\n",
    "\n",
    "        return frames\n",
    "\n",
    "    def false_fn(self, frames):\n",
    "        frames = tf.slice(\n",
    "            frames,\n",
    "            begin=[0,0,0],\n",
    "            size=[self.num_frames, 543, 3]\n",
    "        )\n",
    "\n",
    "        return frames\n",
    "    \n",
    "    def shape_list(self, tensor):\n",
    "        \"\"\"\n",
    "        Deal with dynamic shape in tensorflow cleanly.\n",
    "        Args:\n",
    "            tensor (`tf.Tensor` or `np.ndarray`): The tensor we want the shape of.\n",
    "        Returns:\n",
    "            `List[int]`: The shape of the tensor as a list.\n",
    "        \"\"\"\n",
    "        if isinstance(tensor, np.ndarray):\n",
    "            return list(tensor.shape)\n",
    "\n",
    "        dynamic = tf.shape(tensor)\n",
    "\n",
    "        if tensor.shape == tf.TensorShape(None):\n",
    "            return dynamic\n",
    "\n",
    "        static = tensor.shape.as_list()\n",
    "\n",
    "        return [dynamic[i] if s is None else s for i, s in enumerate(static)]\n",
    "\n",
    "    def __call__(self, frames):\n",
    "        n_frames, _, _ = self.shape_list(frames)\n",
    "        \n",
    "        # nan to num\n",
    "        frames = tf.where(tf.math.is_nan(frames), 0.0, frames)\n",
    "\n",
    "        # sample frames\n",
    "        frames = tf.cond(\n",
    "            tf.less(n_frames, NUM_FRAMES),\n",
    "            true_fn = lambda: true_fn(frames, n_frames),\n",
    "            false_fn = lambda: false_fn(frames),\n",
    "        )\n",
    "\n",
    "        return tf.expand_dims(frames, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f299422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 16, 543, 3)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 16, 468, 3)  0           ['input_1[0][0]']                \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " conv_lstm1d (ConvLSTM1D)       (None, 461, 32)      35968       ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 454, 32)      8224        ['conv_lstm1d[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 16, 21, 3)   0           ['input_1[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3 (Sl  (None, 16, 21, 3)   0           ['input_1[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2 (Sl  (None, 16, 33, 3)   0           ['input_1[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 227, 32)      0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_lstm1d_1 (ConvLSTM1D)     (None, 14, 32)       35968       ['tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv_lstm1d_2 (ConvLSTM1D)     (None, 14, 32)       35968       ['tf.__operators__.getitem_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv_lstm1d_3 (ConvLSTM1D)     (None, 26, 32)       35968       ['tf.__operators__.getitem_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 220, 64)      16448       ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 7, 64)        16448       ['conv_lstm1d_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 7, 64)        16448       ['conv_lstm1d_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 19, 64)       16448       ['conv_lstm1d_3[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 110, 64)     0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 3, 64)       0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 3, 64)       0           ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 9, 64)       0           ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 110, 64)      0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 3, 64)        0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 3, 64)        0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 9, 64)        0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 125, 64)      0           ['dropout[0][0]',                \n",
      "                                                                  'dropout_1[0][0]',              \n",
      "                                                                  'dropout_2[0][0]',              \n",
      "                                                                  'dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 8000)         0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 250)          2000250     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,218,138\n",
      "Trainable params: 2,218,138\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"models/baseline\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8322ef6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TFLiteModel(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    TensorFlow Lite model that takes input tensors and applies:\n",
    "        – a preprocessing model\n",
    "        – the ASL model \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, asl_model):\n",
    "        \"\"\"\n",
    "        Initializes the TFLiteModel with the specified feature generation model and main model.\n",
    "        \"\"\"\n",
    "        super(TFLiteModel, self).__init__()\n",
    "\n",
    "        # Load the feature generation and main models\n",
    "        self.prep_inputs = DataPreprocessing()\n",
    "        self.model = model\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, 543, 3], dtype=tf.float32, name='inputs')])\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Applies the feature generation model and main model to the input tensors.\n",
    "\n",
    "        Args:\n",
    "            inputs: Input tensor with shape [batch_size, 543, 3].\n",
    "\n",
    "        Returns:\n",
    "            A dictionary with a single key 'outputs' and corresponding output tensor.\n",
    "        \"\"\"\n",
    "        x = self.prep_inputs(tf.cast(inputs, dtype=tf.float32))\n",
    "        outputs = self.model(x)[0, :]\n",
    "\n",
    "        # Return a dictionary with the output tensor\n",
    "        return {'outputs': outputs}\n",
    "\n",
    "tflite_keras_model = TFLiteModel(model)\n",
    "demo_output = tflite_keras_model(load_relevant_data_subset(SAMPLE_FILE))[\"outputs\"]\n",
    "np.argmax(demo_output.numpy(), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "275c8e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0khadsct/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0khadsct/assets\n",
      "2023-03-09 22:16:07.988475: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-03-09 22:16:07.988535: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-03-09 22:16:07.989575: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmp0khadsct\n",
      "2023-03-09 22:16:08.035732: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-03-09 22:16:08.035782: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmp0khadsct\n",
      "2023-03-09 22:16:08.186827: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n",
      "2023-03-09 22:16:08.218611: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-03-09 22:16:08.457056: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmp0khadsct\n",
      "2023-03-09 22:16:08.644124: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 654551 microseconds.\n",
      "2023-03-09 22:16:09.342717: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-03-09 22:16:09.909736: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2111] Estimated count of arithmetic ops: 59.193 M  ops, equivalently 29.597 M  MACs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: models/model.tflite (deflated 9%)\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "keras_model_converter = tf.lite.TFLiteConverter.from_keras_model(tflite_keras_model)\n",
    "tflite_model = keras_model_converter.convert()\n",
    "with open('models/model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "!zip submission.zip models/model.tflite\n",
    "\n",
    "import tflite_runtime.interpreter as tflite\n",
    "\n",
    "interpreter = tflite.Interpreter(\"models/model.tflite\")\n",
    "found_signatures = list(interpreter.get_signature_list().keys())\n",
    "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "\n",
    "output = prediction_fn(inputs=load_relevant_data_subset(SAMPLE_FILE))\n",
    "sign = np.argmax(output[\"outputs\"])\n",
    "\n",
    "print(sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320b0e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96639612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0ea15c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f84949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ad4fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bb99b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f28c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851cd6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3514db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c815cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054e69a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
