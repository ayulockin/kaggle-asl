{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-18T15:24:04.434998Z",
     "iopub.status.busy": "2023-03-18T15:24:04.434521Z",
     "iopub.status.idle": "2023-03-18T15:24:18.089826Z",
     "shell.execute_reply": "2023-03-18T15:24:18.088407Z",
     "shell.execute_reply.started": "2023-03-18T15:24:04.434931Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "from glob import glob\n",
    "from argparse import Namespace\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "# Detect TPU, return appropriate distribution strategy\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy() \n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T15:47:17.073076Z",
     "iopub.status.busy": "2023-03-18T15:47:17.072667Z",
     "iopub.status.idle": "2023-03-18T15:47:17.347588Z",
     "shell.execute_reply": "2023-03-18T15:47:17.346311Z",
     "shell.execute_reply.started": "2023-03-18T15:47:17.073041Z"
    }
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "print(wandb.__version__)\n",
    "\n",
    "from wandb.keras import WandbMetricsLogger\n",
    "from wandb.keras import WandbModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T16:28:15.138872Z",
     "iopub.status.busy": "2023-03-18T16:28:15.137599Z",
     "iopub.status.idle": "2023-03-18T16:28:15.146467Z",
     "shell.execute_reply": "2023-03-18T16:28:15.145202Z",
     "shell.execute_reply.started": "2023-03-18T16:28:15.138825Z"
    }
   },
   "outputs": [],
   "source": [
    "def id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n",
    "    return ''.join(random.choice(chars) for _ in range(size))\n",
    "\n",
    "random_id = id_generator(size=8)\n",
    "print('Experiment Id: ', random_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T16:49:31.170495Z",
     "iopub.status.busy": "2023-03-18T16:49:31.170057Z",
     "iopub.status.idle": "2023-03-18T16:49:31.184340Z",
     "shell.execute_reply": "2023-03-18T16:49:31.182905Z",
     "shell.execute_reply.started": "2023-03-18T16:49:31.170457Z"
    }
   },
   "outputs": [],
   "source": [
    "configs = Namespace(\n",
    "    num_frames = 32,\n",
    "    batch_size = 128 if strategy.num_replicas_in_sync==1 else 16*strategy.num_replicas_in_sync,\n",
    "    experiment_id = random_id,\n",
    "    epochs = 30,\n",
    "    resizing_interpolation = \"nearest\",\n",
    "    learning_rate = 1e-4,\n",
    "    num_steps = 1.0,\n",
    "    lips_patch_size = 8,\n",
    "    rh_patch_size = 7,\n",
    "    lh_patch_size = 7,\n",
    "    embed_dim = 128,\n",
    "    num_transformer_blocks=2,\n",
    "    num_heads = 4,\n",
    "    layer_norm_eps = 1e-6\n",
    ")\n",
    "\n",
    "\n",
    "LIP = [\n",
    "    61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
    "    291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
    "    78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "    95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n",
    "]\n",
    "\n",
    "RIGHT_EYE = [\n",
    "    246, 161, 160, 159, 158, 157, 173,\n",
    "    33, 7, 163, 144, 145, 153, 154, 155, 133,\n",
    "    247, 30, 29, 27, 28, 56, 190,\n",
    "    130, 25, 110, 24, 23, 22, 26, 112, 243,\n",
    "    113, 225, 224, 223, 222, 221, 189,\n",
    "    226, 31, 228, 229, 230, 231, 232, 233, 244,\n",
    "    143, 111, 117, 118, 119, 120, 121, 128, 245,\n",
    "]\n",
    "\n",
    "LEFT_EYE = [\n",
    "    466, 387, 386, 385, 384, 398,\n",
    "    263, 249, 390, 373, 374, 380, 381, 382, 362,\n",
    "    467, 260, 259, 257, 258, 286, 414,\n",
    "    359, 255, 339, 254, 253, 252, 256, 341, 463,\n",
    "    342, 445, 444, 443, 442, 441, 413,\n",
    "    446, 261, 448, 449, 450, 451, 452, 453, 464,\n",
    "    372, 340, 346, 347, 348, 349, 350, 357, 465,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T16:49:33.740644Z",
     "iopub.status.busy": "2023-03-18T16:49:33.739202Z",
     "iopub.status.idle": "2023-03-18T16:50:05.665715Z",
     "shell.execute_reply": "2023-03-18T16:50:05.664373Z",
     "shell.execute_reply.started": "2023-03-18T16:49:33.740595Z"
    }
   },
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    project=\"kaggle-asl-tubelet\",\n",
    "    config=configs,\n",
    "    job_type=\"train\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T16:51:56.362533Z",
     "iopub.status.busy": "2023-03-18T16:51:56.362020Z",
     "iopub.status.idle": "2023-03-18T16:51:57.746626Z",
     "shell.execute_reply": "2023-03-18T16:51:57.745165Z",
     "shell.execute_reply.started": "2023-03-18T16:51:56.362481Z"
    }
   },
   "outputs": [],
   "source": [
    "def natural_keys(text):\n",
    "    \"\"\n",
    "    def atoi(text):\n",
    "        return int(text) if text.isdigit() else text\n",
    "    \n",
    "    return [atoi(c) for c in re.split(r'(\\d+)', text)]\n",
    "\n",
    "tfrecords = glob(\"../data/tfrecords-participants/*.tfrec\")\n",
    "tfrecords = sorted(tfrecords, key=natural_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T16:51:57.991163Z",
     "iopub.status.busy": "2023-03-18T16:51:57.990075Z",
     "iopub.status.idle": "2023-03-18T16:51:59.038624Z",
     "shell.execute_reply": "2023-03-18T16:51:59.037057Z",
     "shell.execute_reply.started": "2023-03-18T16:51:57.991116Z"
    }
   },
   "outputs": [],
   "source": [
    "train_tfrecords, valid_tfrecords = tfrecords[:18], tfrecords[18:]\n",
    "print(len(train_tfrecords), len(valid_tfrecords))\n",
    "\n",
    "def parse_sequence(serialized_sequence):\n",
    "    return tf.io.parse_tensor(\n",
    "        serialized_sequence,\n",
    "        out_type=tf.float32,\n",
    "    )\n",
    "\n",
    "\n",
    "def parse_tfrecord_fn(example):\n",
    "    feature_description = {\n",
    "        \"n_frames\": tf.io.FixedLenFeature([], tf.float32),\n",
    "        \"frames\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    \n",
    "    return tf.io.parse_single_example(example, feature_description)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def preprocess_frames(frames):\n",
    "    \"\"\"\n",
    "    In this preprocessing function:\n",
    "    - Fill NaN values to 0.\n",
    "    - Use `tf.image.resize` to interpolate.\n",
    "    \"\"\"\n",
    "    frames = tf.image.resize(\n",
    "        frames, (configs.num_frames, 543), method=configs.resizing_interpolation\n",
    "    )\n",
    "\n",
    "    return frames\n",
    "\n",
    "\n",
    "def normalize_frames(frames):\n",
    "    \"\"\"\n",
    "    Normalize each video\n",
    "    \"\"\"\n",
    "    not_nan_frames = frames[~tf.math.is_nan(frames)]\n",
    "\n",
    "    frames -= tf.math.reduce_mean(not_nan_frames, axis=0, keepdims=True)\n",
    "    frames /= tf.math.reduce_std(not_nan_frames, axis=0, keepdims=True)\n",
    "\n",
    "    frames = tf.where(tf.math.is_finite(frames), frames, tf.zeros_like(frames))\n",
    "    \n",
    "    return frames\n",
    "\n",
    "\n",
    "def parse_data(example):\n",
    "    # Parse Frames\n",
    "    n_frames = example[\"n_frames\"]\n",
    "    frames = tf.reshape(parse_sequence(example[\"frames\"]), shape=(n_frames, 543, 3))\n",
    "    frames = preprocess_frames(frames)\n",
    "    frames = normalize_frames(frames)\n",
    "\n",
    "    # Parse Labels\n",
    "    label = tf.one_hot(example[\"label\"], depth=250)\n",
    "\n",
    "    return frames, label\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = tf.data.TFRecordDataset(train_tfrecords)\n",
    "valid_ds = tf.data.TFRecordDataset(valid_tfrecords)\n",
    "\n",
    "trainloader = (\n",
    "    train_ds\n",
    "    .map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n",
    "    .shuffle(1024)\n",
    "    .map(parse_data, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(configs.batch_size)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "validloader = (\n",
    "    valid_ds\n",
    "    .map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n",
    "    .map(parse_data, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(configs.batch_size)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T16:51:59.042681Z",
     "iopub.status.busy": "2023-03-18T16:51:59.041649Z",
     "iopub.status.idle": "2023-03-18T16:51:59.750387Z",
     "shell.execute_reply": "2023-03-18T16:51:59.749259Z",
     "shell.execute_reply.started": "2023-03-18T16:51:59.042627Z"
    }
   },
   "outputs": [],
   "source": [
    "class TubeletEmbedding1(layers.Layer):\n",
    "    def __init__(self, embed_dim, patch_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.projection = layers.Conv3D(\n",
    "            filters=embed_dim,\n",
    "            kernel_size=(patch_size,patch_size, 1),\n",
    "            strides=(patch_size, patch_size, patch_size),\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        self.flatten = layers.Reshape(target_shape=(-1, embed_dim))\n",
    "\n",
    "    def call(self, videos):\n",
    "        projected_patches = self.projection(videos)\n",
    "        flattened_patches = self.flatten(projected_patches)\n",
    "        return flattened_patches\n",
    "\n",
    "\n",
    "class TubeletEmbedding2(layers.Layer):\n",
    "    def __init__(self, embed_dim, patch_sizes, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        assert len(patch_sizes) == 3 # lips, right_hand, left_hand\n",
    "        lips_patch_size, rh_patch_size, lh_patch_size = patch_sizes[0], patch_sizes[1], patch_sizes[2]\n",
    "\n",
    "        self.lips_projection = layers.Conv3D(\n",
    "            filters=embed_dim,\n",
    "            kernel_size=(lips_patch_size,lips_patch_size, 1),\n",
    "            strides=lips_patch_size,\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        self.rh_projection = layers.Conv3D(\n",
    "            filters=embed_dim,\n",
    "            kernel_size=(rh_patch_size,rh_patch_size, 1),\n",
    "            strides=rh_patch_size,\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        self.lh_projection = layers.Conv3D(\n",
    "            filters=embed_dim,\n",
    "            kernel_size=(lh_patch_size,lh_patch_size, 1),\n",
    "            strides=lh_patch_size,\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        \n",
    "        self.concat = layers.Concatenate(axis=2)\n",
    "        self.flatten = layers.Reshape(target_shape=(-1, embed_dim))\n",
    "        self.layer_norm = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        lips, rh, lh = inputs[:,:,0:40,:, tf.newaxis], inputs[:,:,40:61,:, tf.newaxis], inputs[:,:,61:82,:, tf.newaxis]\n",
    "        lips_projected = self.lips_projection(lips)\n",
    "        rh_projected = self.rh_projection(rh)\n",
    "        lh_projected = self.lh_projection(lh)\n",
    "        projected_patches = self.concat([lips_projected, rh_projected, rh_projected])\n",
    "        flattened_patches = self.flatten(projected_patches)\n",
    "        flattened_patched = self.layer_norm(flattened_patches)\n",
    "        return flattened_patches\n",
    "    \n",
    "    \n",
    "class PositionalEncoder(layers.Layer): # Can I use sine+cosine positional encoder? or rotatory encoder?\n",
    "    def __init__(self, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        _, num_tokens, _ = input_shape\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_tokens, output_dim=self.embed_dim\n",
    "        )\n",
    "        self.positions = tf.range(start=0, limit=num_tokens, delta=1)\n",
    "\n",
    "    def call(self, encoded_tokens):\n",
    "        # Encode the positions and add it to the encoded tokens\n",
    "        encoded_positions = self.position_embedding(self.positions)\n",
    "        encoded_tokens = encoded_tokens + encoded_positions\n",
    "        return encoded_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "    self.add = tf.keras.layers.Add()\n",
    "    \n",
    "    \n",
    "class GlobalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x)\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "class FeedForward(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.seq = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),\n",
    "      tf.keras.layers.Dense(d_model),\n",
    "      tf.keras.layers.Dropout(dropout_rate)\n",
    "    ])\n",
    "    self.add = tf.keras.layers.Add()\n",
    "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.add([x, self.seq(x)])\n",
    "    x = self.layer_norm(x) \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.self_attention = GlobalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.self_attention(x)\n",
    "    x = self.ffn(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "class ViViTEncoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEncoder(embed_dim=d_model)\n",
    "\n",
    "    self.enc_layers = [\n",
    "        EncoderLayer(d_model=d_model,\n",
    "                     num_heads=num_heads,\n",
    "                     dff=4*d_model,\n",
    "                     dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "  def call(self, x):\n",
    "    # `x` is token-IDs shape: (batch, seq_len)\n",
    "    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "    \n",
    "    # Add dropout.\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x)\n",
    "\n",
    "    return x  # Shape `(batch_size, seq_len, d_model)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T16:52:06.271538Z",
     "iopub.status.busy": "2023-03-18T16:52:06.271118Z",
     "iopub.status.idle": "2023-03-18T16:52:07.293333Z",
     "shell.execute_reply": "2023-03-18T16:52:07.292010Z",
     "shell.execute_reply.started": "2023-03-18T16:52:06.271491Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_vivit_classifier(\n",
    "    tubelet_embedder,\n",
    "    positional_encoder,\n",
    "    num_layers=configs.num_transformer_blocks,\n",
    "    num_heads=configs.num_heads,\n",
    "    embed_dim=configs.embed_dim,\n",
    "    layer_norm_eps=configs.layer_norm_eps,\n",
    "):\n",
    "    # Get the input layer\n",
    "    inputs = layers.Input(shape=(32, 543, 3))\n",
    "\n",
    "    # Get lips, right hand and left hand\n",
    "    lip_inputs = tf.gather(inputs, indices=LIP, axis=2)\n",
    "    left_hand_inputs = inputs[:, :, 468:489, :]\n",
    "    right_hand_inputs = inputs[:, :, 522:, :]\n",
    "\n",
    "    landmarks = tf.keras.layers.Concatenate(axis=2)(\n",
    "        [lip_inputs, right_hand_inputs, left_hand_inputs]\n",
    "    )\n",
    "    \n",
    "    # Create patches.\n",
    "    patches = tubelet_embedder(landmarks)\n",
    "        \n",
    "    # Apply Encoder\n",
    "    encoder_output = ViViTEncoder(num_layers, embed_dim, num_heads)(patches)\n",
    "    \n",
    "    # Layer normalization and Global average pooling.\n",
    "    representation = layers.LayerNormalization(epsilon=layer_norm_eps)(encoder_output)\n",
    "    representation = representation[:,0]\n",
    "\n",
    "    # Classify outputs.\n",
    "    outputs = layers.Dense(units=250, activation=\"softmax\")(representation)\n",
    "\n",
    "    # Create the Keras model.\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T16:52:09.118526Z",
     "iopub.status.busy": "2023-03-18T16:52:09.118078Z",
     "iopub.status.idle": "2023-03-18T16:52:12.352284Z",
     "shell.execute_reply": "2023-03-18T16:52:12.351288Z",
     "shell.execute_reply.started": "2023-03-18T16:52:09.118483Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "with strategy.scope():\n",
    "    tubelet_embedder = TubeletEmbedding2(\n",
    "        configs.embed_dim,\n",
    "        patch_sizes=(configs.lips_patch_size, configs.rh_patch_size, configs.lh_patch_size)\n",
    "    )\n",
    "    positional_encoder = PositionalEncoder(configs.embed_dim)\n",
    "    model = create_vivit_classifier(tubelet_embedder, positional_encoder)\n",
    "\n",
    "total_steps = 585*configs.epochs\n",
    "decay_steps = total_steps*configs.num_steps\n",
    "\n",
    "# cosine_decay_scheduler = tf.keras.optimizers.schedules.CosineDecay(\n",
    "#     initial_learning_rate = configs.learning_rate,\n",
    "#     decay_steps = decay_steps,\n",
    "#     alpha=0.1\n",
    "# )\n",
    "\n",
    "model.compile(\n",
    "    tf.keras.optimizers.Adam(configs.learning_rate),\n",
    "    \"binary_crossentropy\",\n",
    "    metrics=[\"acc\"]\n",
    ")\n",
    "\n",
    "model.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T16:52:17.202096Z",
     "iopub.status.busy": "2023-03-18T16:52:17.201656Z",
     "iopub.status.idle": "2023-03-18T16:52:18.907535Z",
     "shell.execute_reply": "2023-03-18T16:52:18.906084Z",
     "shell.execute_reply.started": "2023-03-18T16:52:17.202059Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T16:52:30.670810Z",
     "iopub.status.busy": "2023-03-18T16:52:30.669303Z",
     "iopub.status.idle": "2023-03-18T17:04:18.889583Z",
     "shell.execute_reply": "2023-03-18T17:04:18.888327Z",
     "shell.execute_reply.started": "2023-03-18T16:52:30.670756Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "earlystopper = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=7,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "# checkpoint_options = tf.saved_model.SaveOptions(experimental_io_device=\"/job:localhost\")\n",
    "\n",
    "callbacks = [\n",
    "#     earlystopper,\n",
    "#     WandbMetricsLogger(log_freq=2),\n",
    "#     WandbModelCheckpoint(\n",
    "#         filepath=f\"model-{configs.experiment_id}\",\n",
    "#         save_best_only=True,\n",
    "#         options=checkpoint_options,\n",
    "#     ),\n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    trainloader,\n",
    "    epochs=configs.epochs,\n",
    "    validation_data=validloader,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loss, eval_acc = model.evaluate(validloader)\n",
    "# wandb.log({\"eval_loss\": eval_loss, \"eval_acc\": eval_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T17:07:27.355809Z",
     "iopub.status.busy": "2023-03-18T17:07:27.355360Z",
     "iopub.status.idle": "2023-03-18T17:07:50.220328Z",
     "shell.execute_reply": "2023-03-18T17:07:50.219145Z",
     "shell.execute_reply.started": "2023-03-18T17:07:27.355771Z"
    }
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
