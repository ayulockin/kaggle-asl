{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4787ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "from glob import glob\n",
    "from argparse import Namespace\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from keras.optimizers import *\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.layers.core import *\n",
    "from keras.layers.convolutional import *\n",
    "from keras import backend as K\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da79a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger\n",
    "from wandb.keras import WandbModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dcc597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n",
    "    return ''.join(random.choice(chars) for _ in range(size))\n",
    "\n",
    "random_id = id_generator(size=8)\n",
    "print('Experiment Id: ', random_id)\n",
    "\n",
    "\n",
    "configs = Namespace(\n",
    "    num_frames = 32,\n",
    "    batch_size = 128,\n",
    "    epochs = 60,\n",
    "    resizing_interpolation = \"nearest\",\n",
    "    learning_rate = 1e-3,\n",
    "    num_steps = 1.0,\n",
    "    experiment_id = random_id,\n",
    "    num_jcd_features = 3321, # ((82*82)-82)/2\n",
    "    num_classes = 250,\n",
    "    filters = 256,\n",
    ")\n",
    "\n",
    "\n",
    "LIP = [\n",
    "    61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
    "    291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
    "    78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "    95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n",
    "]\n",
    "\n",
    "RIGHT_EYE = [\n",
    "    246, 161, 160, 159, 158, 157, 173,\n",
    "    33, 7, 163, 144, 145, 153, 154, 155, 133,\n",
    "    247, 30, 29, 27, 28, 56, 190,\n",
    "    130, 25, 110, 24, 23, 22, 26, 112, 243,\n",
    "    113, 225, 224, 223, 222, 221, 189,\n",
    "    226, 31, 228, 229, 230, 231, 232, 233, 244,\n",
    "    143, 111, 117, 118, 119, 120, 121, 128, 245,\n",
    "]\n",
    "\n",
    "LEFT_EYE = [\n",
    "    466, 387, 386, 385, 384, 398,\n",
    "    263, 249, 390, 373, 374, 380, 381, 382, 362,\n",
    "    467, 260, 259, 257, 258, 286, 414,\n",
    "    359, 255, 339, 254, 253, 252, 256, 341, 463,\n",
    "    342, 445, 444, 443, 442, 441, 413,\n",
    "    446, 261, 448, 449, 450, 451, 452, 453, 464,\n",
    "    372, 340, 346, 347, 348, 349, 350, 357, 465,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fdd548",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/tfrecords\"\n",
    "\n",
    "\n",
    "def natural_keys(text):\n",
    "    \"\"\n",
    "    def atoi(text):\n",
    "        return int(text) if text.isdigit() else text\n",
    "    \n",
    "    return [atoi(c) for c in re.split(r'(\\d+)', text)]\n",
    "\n",
    "tfrecords = sorted(glob(f\"{data_path}/*.tfrec\"), key=natural_keys)\n",
    "len(tfrecords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e318752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfrecords, valid_tfrecords = tfrecords[:19], tfrecords[19:]\n",
    "\n",
    "def parse_sequence(serialized_sequence):\n",
    "    return tf.io.parse_tensor(\n",
    "        serialized_sequence,\n",
    "        out_type=tf.float32,\n",
    "    )\n",
    "\n",
    "\n",
    "def parse_tfrecord_fn(example):\n",
    "    feature_description = {\n",
    "        \"n_frames\": tf.io.FixedLenFeature([], tf.float32),\n",
    "        \"frames\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    \n",
    "    return tf.io.parse_single_example(example, feature_description)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def preprocess_frames(frames):\n",
    "    \"\"\"\n",
    "    In this preprocessing function:\n",
    "    - Fill NaN values to 0.\n",
    "    - Use `tf.image.resize` to interpolate.\n",
    "    \"\"\"\n",
    "    frames = tf.where(tf.math.is_nan(frames), 0.0, frames)\n",
    "\n",
    "    frames = tf.image.resize(\n",
    "        frames, (configs.num_frames, 543), method=configs.resizing_interpolation\n",
    "    )\n",
    "\n",
    "    return frames\n",
    "\n",
    "\n",
    "def parse_data(example):\n",
    "    # Parse Frames\n",
    "    n_frames = example[\"n_frames\"]\n",
    "    frames = tf.reshape(parse_sequence(example[\"frames\"]), shape=(n_frames, 543, 3))\n",
    "    frames = preprocess_frames(frames)\n",
    "    \n",
    "    # Parse Labels\n",
    "    label = tf.one_hot(example[\"label\"], depth=250)\n",
    "\n",
    "    return frames, label\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = tf.data.TFRecordDataset(train_tfrecords)\n",
    "valid_ds = tf.data.TFRecordDataset(valid_tfrecords)\n",
    "\n",
    "trainloader = (\n",
    "    train_ds\n",
    "    .map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n",
    "    .shuffle(1024)\n",
    "    .map(parse_data, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(128)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "validloader = (\n",
    "    valid_ds\n",
    "    .map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n",
    "    .map(parse_data, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(128)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ba339f",
   "metadata": {},
   "source": [
    "# JCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1ad035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_JCD(S_k):\n",
    "    # S_k shape is (num_frames, num_joints, depth)\n",
    "    # Compute pairwise euclidean distance \n",
    "    d = tf.reduce_sum((tf.expand_dims(S_k, 3)-tf.expand_dims(S_k, 2))**2,4)\n",
    "    d = tf.sqrt(d)\n",
    "    \n",
    "    # Get lower triangle to reduce redundancy\n",
    "    d = tf.linalg.LinearOperatorLowerTriangular(d).to_dense()\n",
    "    \n",
    "    # Extract and flatten lower triangle\n",
    "    ones = tf.ones_like(d)\n",
    "    mask_a = tf.linalg.band_part(ones, -1, 0) # Lower triangle mask of 0s and 1s\n",
    "    mask_b = tf.linalg.band_part(ones, 0, 0)  # Diagonal mask of 0s and 1s\n",
    "    mask = tf.cast(mask_a - mask_b, dtype=tf.bool) # Desired mask\n",
    "\n",
    "    jcd = tf.boolean_mask(d, mask)\n",
    "    \n",
    "    return jcd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87193d9",
   "metadata": {},
   "source": [
    "# Motion\n",
    "\n",
    "M_k_slow = S_k_plus_1 - S_k (k = 1,2,3,...,K-1)\n",
    "\n",
    "[(S_2-S_1), (S_3-S_2), .....]\n",
    "\n",
    "M_k_fast = S_k_plus_2 - S_k (k = 1,3,5.....,K-2)\n",
    "\n",
    "[(S_3-S_1), (S_5-S_3), .....]\n",
    "\n",
    "\n",
    "S_k is the frame. S_k_plus_1 and S_k_plus_2 are behind/ahead S_k resp.\n",
    "\n",
    "Part of DDNet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27baccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joints_diff(x):\n",
    "    H, W = x.get_shape()[1], x.get_shape()[2]\n",
    "    x = tf.subtract(x[:, 1:, ...], x[:, :-1, ...])\n",
    "    x = tf.image.resize(x, size=[H, W], method=\"nearest\")\n",
    "    return x\n",
    "\n",
    "\n",
    "def joints_motion(P, frame_l):\n",
    "    P_diff_slow = Lambda(lambda x: joints_diff(x))(P)\n",
    "    P_diff_slow = Reshape((frame_l, -1), name=\"slow_reshape\")(P_diff_slow)\n",
    "\n",
    "    P_fast = Lambda(lambda x: x[:, ::2, ...])(P)\n",
    "    P_diff_fast = Lambda(lambda x: joints_diff(x))(P_fast)\n",
    "    P_diff_fast = Reshape((int(frame_l / 2), -1), name=\"fast_reshape\")(P_diff_fast)\n",
    "\n",
    "    return P_diff_slow, P_diff_fast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4d9f1c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5176dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jcd_embedding(x, filters, num_jcd_features):\n",
    "    # Project down\n",
    "    x = EinsumDense(\"abc,cd->abd\", output_shape=(None, num_jcd_features//4), bias_axes=\"d\")(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    x = EinsumDense(\"abc,cd->abd\", output_shape=(None, num_jcd_features//8), bias_axes=\"d\")(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    \n",
    "\n",
    "    # Local relationship between sequences \n",
    "    x = Conv1D(filters, 3, strides=1, dilation_rate=1, padding=\"same\")(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    \n",
    "    x = Conv1D(filters, 3, strides=2, dilation_rate=1, padding=\"same\")(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    \n",
    "    x = Conv1D(filters, 3, strides=2, dilation_rate=1, padding=\"same\")(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_slow_motion_embedding(x, filters):    \n",
    "    # Local relationship between sequences \n",
    "    x = Conv1D(filters, 3, strides=1, dilation_rate=1, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    \n",
    "    x = Conv1D(filters, 3, strides=2, dilation_rate=1, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    \n",
    "    x = Conv1D(filters, 3, strides=2, dilation_rate=1, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def get_fast_motion_embedding(x, filters):    \n",
    "    # Local relationship between sequences \n",
    "    x = Conv1D(filters, 3, strides=1, dilation_rate=1, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    \n",
    "    x = Conv1D(filters, 3, strides=2, dilation_rate=1, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    \n",
    "    x = Conv1D(filters, 3, strides=1, dilation_rate=1, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceb4275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DDNet(num_jcd_features, filters, num_frames):\n",
    "    inputs = Input(shape=(num_frames, 543, 3))\n",
    "    \n",
    "    lip_inputs = tf.gather(inputs, indices=LIP, axis=2)\n",
    "    left_hand_inputs = inputs[:, :, 468:489, :]\n",
    "    right_hand_inputs = inputs[:, :,522:,:]\n",
    "    joints = tf.keras.layers.Concatenate(axis=2)(\n",
    "        [lip_inputs, right_hand_inputs, left_hand_inputs]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # JCD\n",
    "    jcd = compute_JCD(joints)\n",
    "    jcd = tf.reshape(jcd, (-1, num_frames, num_jcd_features))\n",
    "    jcd_embedding = get_jcd_embedding(jcd, 256, num_jcd_features)\n",
    "    \n",
    "    # Slow and Fast Motion\n",
    "    slow_motion, fast_motion = joints_motion(joints, num_frames)\n",
    "    slow_embedding = get_slow_motion_embedding(slow_motion, 256)\n",
    "    fast_embedding = get_fast_motion_embedding(fast_motion, 256)\n",
    "    \n",
    "    # Merge embeddings\n",
    "    x = Concatenate()([jcd_embedding, slow_embedding, fast_embedding])\n",
    "    \n",
    "    # Learn from the embedding\n",
    "    x = Conv1D(256, 3, strides=2, dilation_rate=1, padding=\"same\")(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    \n",
    "    x = Conv1D(256, 3, strides=2, dilation_rate=1, padding=\"same\")(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    x = Dense(250, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687bdae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_JCDNet(num_jcd_features, filters, num_frames):\n",
    "    inputs = Input(shape=(num_frames, 543, 3))\n",
    "    \n",
    "    lip_inputs = tf.gather(inputs, indices=LIP, axis=2)\n",
    "    left_hand_inputs = inputs[:, :, 468:489, :]\n",
    "    right_hand_inputs = inputs[:, :,522:,:]\n",
    "    joints = tf.keras.layers.Concatenate(axis=2)(\n",
    "        [lip_inputs, right_hand_inputs, left_hand_inputs]\n",
    "    )\n",
    "    \n",
    "    # JCD\n",
    "    jcd = compute_JCD(joints)\n",
    "    jcd = tf.reshape(jcd, (-1, num_frames, num_jcd_features))\n",
    "    jcd_embedding = get_jcd_embedding(jcd, 256, num_jcd_features)\n",
    "    \n",
    "    # Learn from the embedding\n",
    "    x = Conv1D(256, 3, strides=2, dilation_rate=1, padding=\"same\")(jcd_embedding)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = SpatialDropout1D(0.3)(x)\n",
    "\n",
    "    x = Conv1D(256, 3, strides=2, dilation_rate=1, padding=\"same\")(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = SpatialDropout1D(0.3)(x)\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    x = Dense(250, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56068ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MotionNet(num_jcd_features, filters, num_frames):\n",
    "    inputs = Input(shape=(num_frames, 543, 3))\n",
    "    \n",
    "    lip_inputs = tf.gather(inputs, indices=LIP, axis=2)\n",
    "    left_hand_inputs = inputs[:, :, 468:489, :]\n",
    "    right_hand_inputs = inputs[:, :,522:,:]\n",
    "    joints = tf.keras.layers.Concatenate(axis=2)(\n",
    "        [lip_inputs, right_hand_inputs, left_hand_inputs]\n",
    "    )\n",
    "    \n",
    "    # Slow and Fast Motion\n",
    "    slow_motion, fast_motion = joints_motion(joints, num_frames)\n",
    "    slow_embedding = get_slow_motion_embedding(slow_motion, 256)\n",
    "    fast_embedding = get_fast_motion_embedding(fast_motion, 256)\n",
    "    \n",
    "    # Merge embeddings\n",
    "    x = Concatenate()([slow_embedding, fast_embedding])\n",
    "    \n",
    "    # Learn from the embedding\n",
    "    x = Conv1D(256, 3, strides=2, dilation_rate=1, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = SpatialDropout1D(0.3)(x)\n",
    "    \n",
    "    x = Conv1D(256, 3, strides=2, dilation_rate=1, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = SpatialDropout1D(0.3)(x)\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "    x = Dense(250, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b84476",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = get_JCDNet(\n",
    "    num_jcd_features=configs.num_jcd_features,\n",
    "    filters=configs.filters,\n",
    "    num_frames=configs.num_frames\n",
    ")\n",
    "    \n",
    "# total_steps = 585*configs.epochs\n",
    "# decay_steps = total_steps*configs.num_steps\n",
    "\n",
    "# cosine_decay_scheduler = tf.keras.optimizers.schedules.CosineDecay(\n",
    "#     initial_learning_rate = configs.learning_rate,\n",
    "#     decay_steps = decay_steps,\n",
    "#     alpha=0.1\n",
    "# )\n",
    "\n",
    "model.compile(\n",
    "    tf.keras.optimizers.Adam(1e-3),\n",
    "    \"binary_crossentropy\",\n",
    "    metrics=[\"acc\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30c24b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad1ef40",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    project=\"kaggle-asl\",\n",
    "    name=f\"ddnet-{configs.experiment_id}\",\n",
    "    config=configs,\n",
    "    job_type=\"train\",\n",
    ")\n",
    "\n",
    "earlystopper = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=8,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "#     earlystopper,\n",
    "    WandbMetricsLogger(log_freq=2),\n",
    "#     WandbModelCheckpoint(\n",
    "#         filepath=f\"../models/ddnet-{configs.experiment_id}\",\n",
    "#         save_best_only=True,\n",
    "#     ),\n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    trainloader,\n",
    "    epochs=configs.epochs,\n",
    "    validation_data=validloader,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a7409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loss, eval_acc = model.evaluate(validloader)\n",
    "wandb.log({\"eval_loss\": eval_loss, \"eval_acc\": eval_acc})\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d1f29f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
