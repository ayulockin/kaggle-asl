{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c2ab37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 22:54:51.297516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-17 22:54:51.501847: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-17 22:54:52.527878: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.7/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-04-17 22:54:52.528032: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.7/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-04-17 22:54:52.528049: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import math\n",
    "import string\n",
    "import random\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from argparse import Namespace\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38f24245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 22:54:53.728514: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-17 22:54:53.743037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-17 22:54:53.743451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-17 22:54:53.744622: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-17 22:54:53.745794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-17 22:54:53.746208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-17 22:54:53.746622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-17 22:54:54.522161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-17 22:54:54.522641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-17 22:54:54.523009: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-17 22:54:54.523340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15002 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41c8b606",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_JOINTS = 543\n",
    "\n",
    "LIP = [\n",
    "    61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
    "    291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
    "#     78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "#     95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n",
    "]\n",
    "\n",
    "RIGHT_EYE = [\n",
    "    246, 161, 160, 159, 158, 157, 173,\n",
    "    33, 7, 163, 144, 145, 153, 154, 155, 133,\n",
    "    247, 30, 29, 27, 28, 56, 190,\n",
    "    130, 25, 110, 24, 23, 22, 26, 112, 243,\n",
    "    113, 225, 224, 223, 222, 221, 189,\n",
    "    226, 31, 228, 229, 230, 231, 232, 233, 244,\n",
    "    143, 111, 117, 118, 119, 120, 121, 128, 245,\n",
    "]\n",
    "\n",
    "LEFT_EYE = [\n",
    "    466, 387, 386, 385, 384, 398,\n",
    "    263, 249, 390, 373, 374, 380, 381, 382, 362,\n",
    "    467, 260, 259, 257, 258, 286, 414,\n",
    "    359, 255, 339, 254, 253, 252, 256, 341, 463,\n",
    "    342, 445, 444, 443, 442, 441, 413,\n",
    "    446, 261, 448, 449, 450, 451, 452, 453, 464,\n",
    "    372, 340, 346, 347, 348, 349, 350, 357, 465,\n",
    "]\n",
    "\n",
    "LEFT_HAND = [\n",
    "    468, 469, 470, 471, 472, 473, 474, 475,\n",
    "    476, 477, 478, 479, 480, 481, 482, 483,\n",
    "    484, 485, 486, 487, 488\n",
    "]\n",
    "\n",
    "RIGHT_HAND = [\n",
    "    522, 523, 524, 525, 526, 527, 528, 529,\n",
    "    530, 531, 532, 533, 534, 535, 536, 537,\n",
    "    538, 539, 540, 541, 542\n",
    "]\n",
    "\n",
    "POSE = [\n",
    "    489, 490, 491, 492, 493, 494, 495, 496, 497,\n",
    "    498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
    "    507, 508, 509, 510, 511, 512, 513, 514, 515,\n",
    "    516, 517, 518, 519, 520, 521\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b48a63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/tfrecords/stratified_split_0.tfrec', '../data/tfrecords/stratified_split_1.tfrec', '../data/tfrecords/stratified_split_2.tfrec', '../data/tfrecords/stratified_split_3.tfrec', '../data/tfrecords/stratified_split_4.tfrec', '../data/tfrecords/stratified_split_5.tfrec', '../data/tfrecords/stratified_split_6.tfrec', '../data/tfrecords/stratified_split_7.tfrec', '../data/tfrecords/stratified_split_8.tfrec', '../data/tfrecords/stratified_split_9.tfrec', '../data/tfrecords/stratified_split_10.tfrec', '../data/tfrecords/stratified_split_11.tfrec', '../data/tfrecords/stratified_split_12.tfrec', '../data/tfrecords/stratified_split_13.tfrec', '../data/tfrecords/stratified_split_14.tfrec', '../data/tfrecords/stratified_split_15.tfrec', '../data/tfrecords/stratified_split_16.tfrec', '../data/tfrecords/stratified_split_17.tfrec', '../data/tfrecords/stratified_split_18.tfrec', '../data/tfrecords/stratified_split_19.tfrec', '../data/tfrecords/stratified_split_20.tfrec', '../data/tfrecords/stratified_split_21.tfrec', '../data/tfrecords/stratified_split_22.tfrec', '../data/tfrecords/stratified_split_23.tfrec']\n"
     ]
    }
   ],
   "source": [
    "def natural_keys(text):\n",
    "    \"\"\n",
    "    def atoi(text):\n",
    "        return int(text) if text.isdigit() else text\n",
    "    \n",
    "    return [atoi(c) for c in re.split(r'(\\d+)', text)]\n",
    "\n",
    "tfrecords = glob(\"../data/tfrecords/*.tfrec\")\n",
    "tfrecords = sorted(tfrecords, key=natural_keys)\n",
    "print(tfrecords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e689d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sequence_raw(serialized_sequence):\n",
    "    return tf.io.parse_tensor(\n",
    "        serialized_sequence,\n",
    "        out_type=tf.float32,\n",
    "    )\n",
    "\n",
    "\n",
    "def parse_tfrecord_fn(example):\n",
    "    feature_description = {\n",
    "        \"n_frames\": tf.io.FixedLenFeature([], tf.float32),\n",
    "        \"frames\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    \n",
    "    return tf.io.parse_single_example(example, feature_description)\n",
    "\n",
    "\n",
    "def parse_data(example):\n",
    "    # Parse Frames\n",
    "    n_frames = example[\"n_frames\"]\n",
    "    frames = tf.reshape(parse_sequence_raw(example[\"frames\"]), shape=(n_frames, 543, 3))\n",
    "\n",
    "    # Parse Labels\n",
    "    label = example[\"label\"]\n",
    "\n",
    "    return n_frames, frames, label\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "\n",
    "def get_dataloader(tfrecord):\n",
    "    ds = tf.data.TFRecordDataset(tfrecord)\n",
    "\n",
    "    dataloader = (\n",
    "        ds\n",
    "        .shuffle(1024)\n",
    "        .map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n",
    "        .map(parse_data, num_parallel_calls=AUTOTUNE)\n",
    "        .prefetch(AUTOTUNE)\n",
    "    )\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fde36949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "\n",
    "def int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.numpy()]))\n",
    "\n",
    "\n",
    "def serialize_sequence(sequence):\n",
    "    \"\"\"Serialize the multidimentional tensor\"\"\"\n",
    "    return tf.io.serialize_tensor(sequence)\n",
    "\n",
    "\n",
    "def parse_sequence(serialized_sequence):\n",
    "    return tf.io.parse_tensor(\n",
    "        serialized_sequence,\n",
    "        out_type=tf.uint8,\n",
    "    )\n",
    "\n",
    "\n",
    "def create_example(n_frames, sequence, label):\n",
    "    feature = {\n",
    "        \"n_frames\": float_feature(n_frames),\n",
    "        \"frames\": bytes_feature(serialize_sequence(sequence)),\n",
    "        \"label\": int64_feature(label),\n",
    "    }\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f7d086d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_a_heatmap(arr, centers, max_values):\n",
    "    \"\"\"Generate pseudo heatmap for one keypoint in one frame.\n",
    "\n",
    "    Args:\n",
    "        arr (np.ndarray): The array to store the generated heatmaps. Shape: img_h * img_w.\n",
    "        centers (np.ndarray): The coordinates of corresponding keypoints (of multiple persons). Shape: M * 2.\n",
    "        max_values (np.ndarray): The max values of each keypoint. Shape: M.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The generated pseudo heatmap.\n",
    "    \"\"\"\n",
    "\n",
    "    sigma = 0.1\n",
    "    img_h, img_w = arr.shape\n",
    "\n",
    "    for center, max_value in zip(centers, max_values):\n",
    "        mu_x, mu_y = center[0], center[1]\n",
    "        if not (np.isnan(mu_x) and np.isnan(mu_y)):\n",
    "            # scale\n",
    "            mu_x = min(math.floor(mu_x * img_w), img_w - 1)\n",
    "            mu_y = min(math.floor(mu_y * img_h), img_h - 1)\n",
    "\n",
    "            st_x = max(int(mu_x - 0.5 * sigma), 0)\n",
    "            ed_x = min(int(mu_x + 0.5 * sigma) + 1, img_w)\n",
    "            st_y = max(int(mu_y - 0.5 * sigma), 0)\n",
    "            ed_y = min(int(mu_y + 0.5 * sigma) + 1, img_h)\n",
    "            x = np.arange(st_x, ed_x, 1, np.float32)\n",
    "            y = np.arange(st_y, ed_y, 1, np.float32)\n",
    "\n",
    "            # if the keypoint not in the heatmap coordinate system\n",
    "            if not (len(x) and len(y)):\n",
    "                continue\n",
    "            y = y[:, None]\n",
    "\n",
    "            patch = np.exp(-((x - mu_x)**2 + (y - mu_y)**2) / 2 / sigma**2)\n",
    "            patch = patch * max_value\n",
    "            arr[st_y:ed_y, st_x:ed_x] = np.maximum(arr[st_y:ed_y, st_x:ed_x], patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42b29786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3d_heatmap(ret, human_kps, num_frames):\n",
    "    \n",
    "    for i, frame in enumerate(range(num_frames)):\n",
    "        arr = ret[i]\n",
    "        human = human_kps[i]\n",
    "\n",
    "        x, y = human[:,:1], human[:,1:2]\n",
    "\n",
    "        # TODO: Normalize the whole sequence together\n",
    "        x = (x-np.nanmin(x))/(np.nanmax(x)-np.nanmin(x))\n",
    "        y = (y-np.nanmin(y))/(np.nanmax(y)-np.nanmin(y))\n",
    "\n",
    "        human = np.squeeze(np.array(list(zip(x, y))), axis=-1)\n",
    "\n",
    "        kps = np.expand_dims(human, axis=0)\n",
    "        all_kpscores = np.ones((1,num_frames,NUM_JOINTS), dtype=np.float32)\n",
    "        kpscores = np.ones_like(all_kpscores[:, 0])\n",
    "\n",
    "        num_kp = kps.shape[1]\n",
    "        for i in range(num_kp):\n",
    "            generate_a_heatmap(arr[i], kps[:, i], kpscores[:, i])\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a3ec9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_heatmaps(heatmaps, channel=-1, ratio=8):\n",
    "    # if channel is -1, draw all keypoints / limbs on the same map\n",
    "    import matplotlib.cm as cm\n",
    "    heatmaps = [x.transpose(1, 2, 0) for x in heatmaps]\n",
    "    h, w, _ = heatmaps[0].shape\n",
    "    newh, neww = int(h * ratio), int(w * ratio)\n",
    "\n",
    "    if channel == -1:\n",
    "        heatmaps = [np.max(x, axis=-1) for x in heatmaps]\n",
    "    cmap = cm.viridis\n",
    "    heatmaps = [(cmap(x)[..., :3] * 255).astype(np.uint8) for x in heatmaps]\n",
    "    heatmaps = [cv2.resize(x, (neww, newh)) for x in heatmaps]\n",
    "    return heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40b3a3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_human_nodes(heatmap):\n",
    "    keypoint_humans = []\n",
    "\n",
    "    for arr in heatmap:\n",
    "        keypoint_mapvis = vis_heatmaps(np.expand_dims(arr, axis=0), ratio=1)\n",
    "        keypoint_humans.append(keypoint_mapvis[0])\n",
    "\n",
    "    return np.array(keypoint_humans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "aaa5b9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TFRecords:   0%|                                                  | 0/24 [00:00<?, ?it/s]\n",
      "Reading TFRecord idx: 0: 0it [00:00, ?it/s]\u001b[A\n",
      "TFRecords:   0%|                                                  | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_JOINTS = 107\n",
    "IMG_H = 56\n",
    "IMG_W = 56\n",
    "tfrecords_dir = \"../data/tfrecords_heatmaps_tmp\"\n",
    "os.makedirs(tfrecords_dir, exist_ok=True)\n",
    "\n",
    "for idx, tfrecord in enumerate(tqdm(tfrecords, desc=\"TFRecords: \")):\n",
    "    dataloader = get_dataloader(tfrecord)\n",
    "    \n",
    "    split = tfrecord.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1]\n",
    "    \n",
    "    with tf.io.TFRecordWriter(\n",
    "        tfrecords_dir + f\"/split_{split}.tfrec\"\n",
    "    ) as writer:\n",
    "\n",
    "        for idx, (num_frames, data, label) in enumerate(tqdm(dataloader, desc=f\"Reading TFRecord idx: {split}\")):\n",
    "            faces = tf.gather(data, LIP, axis=1).numpy()\n",
    "            poses = tf.gather(data, POSE, axis=1).numpy()[:,:-8]\n",
    "            rhs = tf.gather(data, RIGHT_HAND, axis=1).numpy()\n",
    "            lhs = tf.gather(data, LEFT_HAND, axis=1).numpy()\n",
    "\n",
    "            humans = np.concatenate([faces, poses, rhs, lhs], axis=1)\n",
    "            num_frames = humans.shape[0]\n",
    "            print(num_frames)\n",
    "            \n",
    "            if num_frames < 32:\n",
    "                humans = tf.image.resize(humans, (32,87), method=\"nearest\").numpy()\n",
    "            else:\n",
    "                # uniform sampling\n",
    "                indices = sorted(np.random.choice(num_frames, 32, replace=False))\n",
    "                humans = humans[indices]\n",
    "\n",
    "            num_frames = humans.shape[0]\n",
    "            ret = np.zeros([num_frames, NUM_JOINTS, IMG_H, IMG_W], dtype=np.float32)\n",
    "\n",
    "            heatmap = get_3d_heatmap(ret, humans, num_frames)\n",
    "\n",
    "            keypoint_humans = draw_human_nodes(heatmap)\n",
    "\n",
    "            example = create_example(\n",
    "                num_frames,\n",
    "                keypoint_humans,\n",
    "                label.numpy()\n",
    "            )\n",
    "\n",
    "            writer.write(example.SerializeToString())\n",
    "\n",
    "            break\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ad2e444f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfrec_path = tfrecords_dir + \"/split_0.tfrec\"\n",
    "raw_dataset = tf.data.TFRecordDataset(tfrec_path)\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5571f7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = parse_tfrecord_fn(next(iter(raw_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "be09f3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=32.0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[\"n_frames\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6192d617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f989324b450>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(tf.reshape(parse_sequence(example[\"frames\"]), shape=(example[\"n_frames\"], 56, 56, 3)).numpy()[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "290b544a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 56, 56, 3)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(parse_sequence(example[\"frames\"]), shape=(example[\"n_frames\"], 56, 56, 3)).numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "95aea60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 8))\n",
    "\n",
    "arr = tf.reshape(parse_sequence(example[\"frames\"]), shape=(example[\"n_frames\"], 56, 56, 3)).numpy()\n",
    "\n",
    "def update(i):\n",
    "    im_normed = arr[i]\n",
    "    ax.imshow(im_normed)\n",
    "    ax.set_title(f\"human_{i}\", fontsize=20)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "\n",
    "anim = FuncAnimation(fig, update, frames=np.arange(0, len(arr)), interval=10)\n",
    "anim.save('humanpose3d-resized1.gif', dpi=80, writer='imagemagick')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1513cf35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
