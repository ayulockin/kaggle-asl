{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed62ecdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "0.27.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import tensorflow_io as tfio\n",
    "print(tfio.__version__)\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bb15fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 23:12:05.352192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-18 23:12:05.366481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-18 23:12:05.366920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-18 23:12:05.369380: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-18 23:12:05.370496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-18 23:12:05.370888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-18 23:12:05.371269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-18 23:12:06.132916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-18 23:12:06.133484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-18 23:12:06.133840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-18 23:12:06.134177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15391 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3f37d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/tfrecord_heatmaps\"\n",
    "\n",
    "\n",
    "def natural_keys(text):\n",
    "    \"\"\n",
    "    def atoi(text):\n",
    "        return int(text) if text.isdigit() else text\n",
    "    \n",
    "    return [atoi(c) for c in re.split(r'(\\d+)', text)]\n",
    "\n",
    "tfrecords = sorted(glob(f\"{data_path}/*.tfrec\"), key=natural_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87b3429d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'TV',\n",
       " 1: 'after',\n",
       " 2: 'airplane',\n",
       " 3: 'all',\n",
       " 4: 'alligator',\n",
       " 5: 'animal',\n",
       " 6: 'another',\n",
       " 7: 'any',\n",
       " 8: 'apple',\n",
       " 9: 'arm',\n",
       " 10: 'aunt',\n",
       " 11: 'awake',\n",
       " 12: 'backyard',\n",
       " 13: 'bad',\n",
       " 14: 'balloon',\n",
       " 15: 'bath',\n",
       " 16: 'because',\n",
       " 17: 'bed',\n",
       " 18: 'bedroom',\n",
       " 19: 'bee',\n",
       " 20: 'before',\n",
       " 21: 'beside',\n",
       " 22: 'better',\n",
       " 23: 'bird',\n",
       " 24: 'black',\n",
       " 25: 'blow',\n",
       " 26: 'blue',\n",
       " 27: 'boat',\n",
       " 28: 'book',\n",
       " 29: 'boy',\n",
       " 30: 'brother',\n",
       " 31: 'brown',\n",
       " 32: 'bug',\n",
       " 33: 'bye',\n",
       " 34: 'callonphone',\n",
       " 35: 'can',\n",
       " 36: 'car',\n",
       " 37: 'carrot',\n",
       " 38: 'cat',\n",
       " 39: 'cereal',\n",
       " 40: 'chair',\n",
       " 41: 'cheek',\n",
       " 42: 'child',\n",
       " 43: 'chin',\n",
       " 44: 'chocolate',\n",
       " 45: 'clean',\n",
       " 46: 'close',\n",
       " 47: 'closet',\n",
       " 48: 'cloud',\n",
       " 49: 'clown',\n",
       " 50: 'cow',\n",
       " 51: 'cowboy',\n",
       " 52: 'cry',\n",
       " 53: 'cut',\n",
       " 54: 'cute',\n",
       " 55: 'dad',\n",
       " 56: 'dance',\n",
       " 57: 'dirty',\n",
       " 58: 'dog',\n",
       " 59: 'doll',\n",
       " 60: 'donkey',\n",
       " 61: 'down',\n",
       " 62: 'drawer',\n",
       " 63: 'drink',\n",
       " 64: 'drop',\n",
       " 65: 'dry',\n",
       " 66: 'dryer',\n",
       " 67: 'duck',\n",
       " 68: 'ear',\n",
       " 69: 'elephant',\n",
       " 70: 'empty',\n",
       " 71: 'every',\n",
       " 72: 'eye',\n",
       " 73: 'face',\n",
       " 74: 'fall',\n",
       " 75: 'farm',\n",
       " 76: 'fast',\n",
       " 77: 'feet',\n",
       " 78: 'find',\n",
       " 79: 'fine',\n",
       " 80: 'finger',\n",
       " 81: 'finish',\n",
       " 82: 'fireman',\n",
       " 83: 'first',\n",
       " 84: 'fish',\n",
       " 85: 'flag',\n",
       " 86: 'flower',\n",
       " 87: 'food',\n",
       " 88: 'for',\n",
       " 89: 'frenchfries',\n",
       " 90: 'frog',\n",
       " 91: 'garbage',\n",
       " 92: 'gift',\n",
       " 93: 'giraffe',\n",
       " 94: 'girl',\n",
       " 95: 'give',\n",
       " 96: 'glasswindow',\n",
       " 97: 'go',\n",
       " 98: 'goose',\n",
       " 99: 'grandma',\n",
       " 100: 'grandpa',\n",
       " 101: 'grass',\n",
       " 102: 'green',\n",
       " 103: 'gum',\n",
       " 104: 'hair',\n",
       " 105: 'happy',\n",
       " 106: 'hat',\n",
       " 107: 'hate',\n",
       " 108: 'have',\n",
       " 109: 'haveto',\n",
       " 110: 'head',\n",
       " 111: 'hear',\n",
       " 112: 'helicopter',\n",
       " 113: 'hello',\n",
       " 114: 'hen',\n",
       " 115: 'hesheit',\n",
       " 116: 'hide',\n",
       " 117: 'high',\n",
       " 118: 'home',\n",
       " 119: 'horse',\n",
       " 120: 'hot',\n",
       " 121: 'hungry',\n",
       " 122: 'icecream',\n",
       " 123: 'if',\n",
       " 124: 'into',\n",
       " 125: 'jacket',\n",
       " 126: 'jeans',\n",
       " 127: 'jump',\n",
       " 128: 'kiss',\n",
       " 129: 'kitty',\n",
       " 130: 'lamp',\n",
       " 131: 'later',\n",
       " 132: 'like',\n",
       " 133: 'lion',\n",
       " 134: 'lips',\n",
       " 135: 'listen',\n",
       " 136: 'look',\n",
       " 137: 'loud',\n",
       " 138: 'mad',\n",
       " 139: 'make',\n",
       " 140: 'man',\n",
       " 141: 'many',\n",
       " 142: 'milk',\n",
       " 143: 'minemy',\n",
       " 144: 'mitten',\n",
       " 145: 'mom',\n",
       " 146: 'moon',\n",
       " 147: 'morning',\n",
       " 148: 'mouse',\n",
       " 149: 'mouth',\n",
       " 150: 'nap',\n",
       " 151: 'napkin',\n",
       " 152: 'night',\n",
       " 153: 'no',\n",
       " 154: 'noisy',\n",
       " 155: 'nose',\n",
       " 156: 'not',\n",
       " 157: 'now',\n",
       " 158: 'nuts',\n",
       " 159: 'old',\n",
       " 160: 'on',\n",
       " 161: 'open',\n",
       " 162: 'orange',\n",
       " 163: 'outside',\n",
       " 164: 'owie',\n",
       " 165: 'owl',\n",
       " 166: 'pajamas',\n",
       " 167: 'pen',\n",
       " 168: 'pencil',\n",
       " 169: 'penny',\n",
       " 170: 'person',\n",
       " 171: 'pig',\n",
       " 172: 'pizza',\n",
       " 173: 'please',\n",
       " 174: 'police',\n",
       " 175: 'pool',\n",
       " 176: 'potty',\n",
       " 177: 'pretend',\n",
       " 178: 'pretty',\n",
       " 179: 'puppy',\n",
       " 180: 'puzzle',\n",
       " 181: 'quiet',\n",
       " 182: 'radio',\n",
       " 183: 'rain',\n",
       " 184: 'read',\n",
       " 185: 'red',\n",
       " 186: 'refrigerator',\n",
       " 187: 'ride',\n",
       " 188: 'room',\n",
       " 189: 'sad',\n",
       " 190: 'same',\n",
       " 191: 'say',\n",
       " 192: 'scissors',\n",
       " 193: 'see',\n",
       " 194: 'shhh',\n",
       " 195: 'shirt',\n",
       " 196: 'shoe',\n",
       " 197: 'shower',\n",
       " 198: 'sick',\n",
       " 199: 'sleep',\n",
       " 200: 'sleepy',\n",
       " 201: 'smile',\n",
       " 202: 'snack',\n",
       " 203: 'snow',\n",
       " 204: 'stairs',\n",
       " 205: 'stay',\n",
       " 206: 'sticky',\n",
       " 207: 'store',\n",
       " 208: 'story',\n",
       " 209: 'stuck',\n",
       " 210: 'sun',\n",
       " 211: 'table',\n",
       " 212: 'talk',\n",
       " 213: 'taste',\n",
       " 214: 'thankyou',\n",
       " 215: 'that',\n",
       " 216: 'there',\n",
       " 217: 'think',\n",
       " 218: 'thirsty',\n",
       " 219: 'tiger',\n",
       " 220: 'time',\n",
       " 221: 'tomorrow',\n",
       " 222: 'tongue',\n",
       " 223: 'tooth',\n",
       " 224: 'toothbrush',\n",
       " 225: 'touch',\n",
       " 226: 'toy',\n",
       " 227: 'tree',\n",
       " 228: 'uncle',\n",
       " 229: 'underwear',\n",
       " 230: 'up',\n",
       " 231: 'vacuum',\n",
       " 232: 'wait',\n",
       " 233: 'wake',\n",
       " 234: 'water',\n",
       " 235: 'wet',\n",
       " 236: 'weus',\n",
       " 237: 'where',\n",
       " 238: 'white',\n",
       " 239: 'who',\n",
       " 240: 'why',\n",
       " 241: 'will',\n",
       " 242: 'wolf',\n",
       " 243: 'yellow',\n",
       " 244: 'yes',\n",
       " 245: 'yesterday',\n",
       " 246: 'yourself',\n",
       " 247: 'yucky',\n",
       " 248: 'zebra',\n",
       " 249: 'zipper'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/sign_to_prediction_index_map.json\") as f:\n",
    "    data = json.load(f)\n",
    "id2label = {v:k for k, v in data.items()}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f6c4b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "train_tfrecords, valid_tfrecords = tfrecords[:19], tfrecords[19:]\n",
    "print(len(train_tfrecords)+len(valid_tfrecords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "428e799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sequence(serialized_sequence):\n",
    "    return tf.io.parse_tensor(\n",
    "        serialized_sequence,\n",
    "        out_type=tf.uint8,\n",
    "    )\n",
    "\n",
    "\n",
    "def parse_tfrecord_fn(example):\n",
    "    feature_description = {\n",
    "        \"n_frames\": tf.io.FixedLenFeature([], tf.float32),\n",
    "        \"frames\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    \n",
    "    return tf.io.parse_single_example(example, feature_description)\n",
    "\n",
    "\n",
    "def preprocess_frames(frames):\n",
    "    \"\"\"This is where different preprocessing logics will be experimented.\"\"\"\n",
    "    # nan to num\n",
    "    frames = (frames - tf.reduce_min(frames))/(tf.reduce_max(frames)-tf.reduce_min(frames))\n",
    "\n",
    "    return frames\n",
    "\n",
    "\n",
    "def parse_data(example):\n",
    "    # Parse Frames\n",
    "    n_frames = example[\"n_frames\"]\n",
    "    frames = tf.reshape(parse_sequence(example[\"frames\"]), shape=(example[\"n_frames\"], 56, 56, 3))\n",
    "    frames = preprocess_frames(frames)\n",
    "    \n",
    "    # Parse Labels\n",
    "    label = tf.one_hot(example[\"label\"], depth=250)\n",
    "\n",
    "    return frames, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95493eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = tf.data.TFRecordDataset(train_tfrecords)\n",
    "valid_ds = tf.data.TFRecordDataset(valid_tfrecords)\n",
    "\n",
    "trainloader = (\n",
    "    train_ds\n",
    "    .shuffle(1024)\n",
    "    .map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n",
    "    .map(parse_data, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(16)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "validloader = (\n",
    "    valid_ds\n",
    "    .map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n",
    "    .map(parse_data, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(16)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a20ce01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 32, 56, 56, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample, label = next(iter(trainloader))\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7914a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A vanilla 3D resnet implementation.\n",
    "\n",
    "Based on Raghavendra Kotikalapudi's 2D implementation\n",
    "keras-resnet (See https://github.com/raghakot/keras-resnet.)\n",
    "\"\"\"\n",
    "from __future__ import (\n",
    "    absolute_import,\n",
    "    division,\n",
    "    print_function,\n",
    "    unicode_literals\n",
    ")\n",
    "import six\n",
    "from math import ceil\n",
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "    Input,\n",
    "    Activation,\n",
    "    Dense,\n",
    "    Flatten\n",
    ")\n",
    "from keras.layers import (\n",
    "    Conv3D,\n",
    "    AveragePooling3D,\n",
    "    MaxPooling3D\n",
    ")\n",
    "from keras.layers import add\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def _bn_relu(input):\n",
    "    \"\"\"Helper to build a BN -> relu block (by @raghakot).\"\"\"\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
    "    return Activation(\"relu\")(norm)\n",
    "\n",
    "\n",
    "def _conv_bn_relu3D(**conv_params):\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\n",
    "        \"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\",\n",
    "                                                l2(1e-4))\n",
    "\n",
    "    def f(input):\n",
    "        conv = Conv3D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, kernel_initializer=kernel_initializer,\n",
    "                      padding=padding,\n",
    "                      kernel_regularizer=kernel_regularizer)(input)\n",
    "        return _bn_relu(conv)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _bn_relu_conv3d(**conv_params):\n",
    "    \"\"\"Helper to build a  BN -> relu -> conv3d block.\"\"\"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\",\n",
    "                                                \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\",\n",
    "                                                l2(1e-4))\n",
    "\n",
    "    def f(input):\n",
    "        activation = _bn_relu(input)\n",
    "        return Conv3D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, kernel_initializer=kernel_initializer,\n",
    "                      padding=padding,\n",
    "                      kernel_regularizer=kernel_regularizer)(activation)\n",
    "    return f\n",
    "\n",
    "\n",
    "def _shortcut3d(input, residual):\n",
    "    \"\"\"3D shortcut to match input and residual and merges them with \"sum\".\"\"\"\n",
    "    stride_dim1 = ceil(input.shape[DIM1_AXIS] \\\n",
    "        / residual.shape[DIM1_AXIS])\n",
    "    stride_dim2 = ceil(input.shape[DIM2_AXIS] \\\n",
    "        / residual.shape[DIM2_AXIS])\n",
    "    stride_dim3 = ceil(input.shape[DIM3_AXIS] \\\n",
    "        / residual.shape[DIM3_AXIS])\n",
    "    equal_channels = residual.shape[CHANNEL_AXIS] \\\n",
    "        == input.shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = input\n",
    "    if stride_dim1 > 1 or stride_dim2 > 1 or stride_dim3 > 1 \\\n",
    "            or not equal_channels:\n",
    "        shortcut = Conv3D(\n",
    "            filters=residual.shape[CHANNEL_AXIS],\n",
    "            kernel_size=(1, 1, 1),\n",
    "            strides=(stride_dim1, stride_dim2, stride_dim3),\n",
    "            kernel_initializer=\"he_normal\", padding=\"valid\",\n",
    "            kernel_regularizer=l2(1e-4)\n",
    "            )(input)\n",
    "    return add([shortcut, residual])\n",
    "\n",
    "\n",
    "def _residual_block3d(block_function, filters, kernel_regularizer, repetitions,\n",
    "                      is_first_layer=False):\n",
    "    def f(input):\n",
    "        for i in range(repetitions):\n",
    "            strides = (1, 1, 1)\n",
    "            if i == 0 and not is_first_layer:\n",
    "                strides = (2, 2, 2)\n",
    "            input = block_function(filters=filters, strides=strides,\n",
    "                                   kernel_regularizer=kernel_regularizer,\n",
    "                                   is_first_block_of_first_layer=(\n",
    "                                       is_first_layer and i == 0)\n",
    "                                   )(input)\n",
    "        return input\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def basic_block(filters, strides=(1, 1, 1), kernel_regularizer=l2(1e-4),\n",
    "                is_first_block_of_first_layer=False):\n",
    "    \"\"\"Basic 3 X 3 X 3 convolution blocks. Extended from raghakot's 2D impl.\"\"\"\n",
    "    def f(input):\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv1 = Conv3D(filters=filters, kernel_size=(3, 3, 3),\n",
    "                           strides=strides, padding=\"same\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=kernel_regularizer\n",
    "                           )(input)\n",
    "        else:\n",
    "            conv1 = _bn_relu_conv3d(filters=filters,\n",
    "                                    kernel_size=(3, 3, 3),\n",
    "                                    strides=strides,\n",
    "                                    kernel_regularizer=kernel_regularizer\n",
    "                                    )(input)\n",
    "\n",
    "        residual = _bn_relu_conv3d(filters=filters, kernel_size=(3, 3, 3),\n",
    "                                   kernel_regularizer=kernel_regularizer\n",
    "                                   )(conv1)\n",
    "        return _shortcut3d(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def bottleneck(filters, strides=(1, 1, 1), kernel_regularizer=l2(1e-4),\n",
    "               is_first_block_of_first_layer=False):\n",
    "    \"\"\"Basic 3 X 3 X 3 convolution blocks. Extended from raghakot's 2D impl.\"\"\"\n",
    "    def f(input):\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv_1_1 = Conv3D(filters=filters, kernel_size=(1, 1, 1),\n",
    "                              strides=strides, padding=\"same\",\n",
    "                              kernel_initializer=\"he_normal\",\n",
    "                              kernel_regularizer=kernel_regularizer\n",
    "                              )(input)\n",
    "        else:\n",
    "            conv_1_1 = _bn_relu_conv3d(filters=filters, kernel_size=(1, 1, 1),\n",
    "                                       strides=strides,\n",
    "                                       kernel_regularizer=kernel_regularizer\n",
    "                                       )(input)\n",
    "\n",
    "        conv_3_3 = _bn_relu_conv3d(filters=filters, kernel_size=(3, 3, 3),\n",
    "                                   kernel_regularizer=kernel_regularizer\n",
    "                                   )(conv_1_1)\n",
    "        residual = _bn_relu_conv3d(filters=filters * 4, kernel_size=(1, 1, 1),\n",
    "                                   kernel_regularizer=kernel_regularizer\n",
    "                                   )(conv_3_3)\n",
    "\n",
    "        return _shortcut3d(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _handle_data_format():\n",
    "    global DIM1_AXIS\n",
    "    global DIM2_AXIS\n",
    "    global DIM3_AXIS\n",
    "    global CHANNEL_AXIS\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        DIM1_AXIS = 1\n",
    "        DIM2_AXIS = 2\n",
    "        DIM3_AXIS = 3\n",
    "        CHANNEL_AXIS = 4\n",
    "    else:\n",
    "        CHANNEL_AXIS = 1\n",
    "        DIM1_AXIS = 2\n",
    "        DIM2_AXIS = 3\n",
    "        DIM3_AXIS = 4\n",
    "\n",
    "\n",
    "def _get_block(identifier):\n",
    "    if isinstance(identifier, six.string_types):\n",
    "        res = globals().get(identifier)\n",
    "        if not res:\n",
    "            raise ValueError('Invalid {}'.format(identifier))\n",
    "        return res\n",
    "    return identifier\n",
    "\n",
    "\n",
    "class Resnet3DBuilder(object):\n",
    "    \"\"\"ResNet3D.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def build(input_shape, num_outputs, block_fn, repetitions, reg_factor):\n",
    "        \"\"\"Instantiate a vanilla ResNet3D keras model.\n",
    "\n",
    "        # Arguments\n",
    "            input_shape: Tuple of input shape in the format\n",
    "            (conv_dim1, conv_dim2, conv_dim3, channels) if dim_ordering='tf'\n",
    "            (filter, conv_dim1, conv_dim2, conv_dim3) if dim_ordering='th'\n",
    "            num_outputs: The number of outputs at the final softmax layer\n",
    "            block_fn: Unit block to use {'basic_block', 'bottlenack_block'}\n",
    "            repetitions: Repetitions of unit blocks\n",
    "        # Returns\n",
    "            model: a 3D ResNet model that takes a 5D tensor (volumetric images\n",
    "            in batch) as input and returns a 1D vector (prediction) as output.\n",
    "        \"\"\"\n",
    "        _handle_data_format()\n",
    "        if len(input_shape) != 4:\n",
    "            raise ValueError(\"Input shape should be a tuple \"\n",
    "                             \"(conv_dim1, conv_dim2, conv_dim3, channels) \"\n",
    "                             \"for tensorflow as backend or \"\n",
    "                             \"(channels, conv_dim1, conv_dim2, conv_dim3) \"\n",
    "                             \"for theano as backend\")\n",
    "\n",
    "        block_fn = _get_block(block_fn)\n",
    "        input = Input(shape=input_shape)\n",
    "        # first conv\n",
    "        conv1 = _conv_bn_relu3D(filters=64, kernel_size=(7, 7, 7),\n",
    "                                strides=(2, 2, 2),\n",
    "                                kernel_regularizer=l2(reg_factor)\n",
    "                                )(input)\n",
    "        pool1 = MaxPooling3D(pool_size=(3, 3, 3), strides=(2, 2, 2),\n",
    "                             padding=\"same\")(conv1)\n",
    "\n",
    "        # repeat blocks\n",
    "        block = pool1\n",
    "        filters = 64\n",
    "        for i, r in enumerate(repetitions):\n",
    "            block = _residual_block3d(block_fn, filters=filters,\n",
    "                                      kernel_regularizer=l2(reg_factor),\n",
    "                                      repetitions=r, is_first_layer=(i == 0)\n",
    "                                      )(block)\n",
    "            filters *= 2\n",
    "\n",
    "        # last activation\n",
    "        block_output = _bn_relu(block)\n",
    "\n",
    "        # average poll and classification\n",
    "        pool2 = AveragePooling3D(pool_size=(block.shape[DIM1_AXIS],\n",
    "                                            block.shape[DIM2_AXIS],\n",
    "                                            block.shape[DIM3_AXIS]),\n",
    "                                 strides=(1, 1, 1))(block_output)\n",
    "        flatten1 = Flatten()(pool2)\n",
    "        if num_outputs > 1:\n",
    "            dense = Dense(units=num_outputs,\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          activation=\"softmax\",\n",
    "                          kernel_regularizer=l2(reg_factor))(flatten1)\n",
    "        else:\n",
    "            dense = Dense(units=num_outputs,\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          activation=\"sigmoid\",\n",
    "                          kernel_regularizer=l2(reg_factor))(flatten1)\n",
    "\n",
    "        model = Model(inputs=input, outputs=dense)\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_18(input_shape, num_outputs, reg_factor=1e-4):\n",
    "        \"\"\"Build resnet 18.\"\"\"\n",
    "        return Resnet3DBuilder.build(input_shape, num_outputs, basic_block,\n",
    "                                     [2, 2, 2, 2], reg_factor=reg_factor)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_34(input_shape, num_outputs, reg_factor=1e-4):\n",
    "        \"\"\"Build resnet 34.\"\"\"\n",
    "        return Resnet3DBuilder.build(input_shape, num_outputs, basic_block,\n",
    "                                     [3, 4, 6, 3], reg_factor=reg_factor)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_50(input_shape, num_outputs, reg_factor=1e-4):\n",
    "        \"\"\"Build resnet 50.\"\"\"\n",
    "        return Resnet3DBuilder.build(input_shape, num_outputs, bottleneck,\n",
    "                                     [3, 4, 6, 3], reg_factor=reg_factor)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_101(input_shape, num_outputs, reg_factor=1e-4):\n",
    "        \"\"\"Build resnet 101.\"\"\"\n",
    "        return Resnet3DBuilder.build(input_shape, num_outputs, bottleneck,\n",
    "                                     [3, 4, 23, 3], reg_factor=reg_factor)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_152(input_shape, num_outputs, reg_factor=1e-4):\n",
    "        \"\"\"Build resnet 152.\"\"\"\n",
    "        return Resnet3DBuilder.build(input_shape, num_outputs, bottleneck,\n",
    "                                     [3, 8, 36, 3], reg_factor=reg_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3ceff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def slowonly():\n",
    "#     inputs = layers.Input(shape=(32,56,56,3))\n",
    "#     # Stem\n",
    "#     x = layers.Conv3D(32, (1,7,7), 1, activation='relu')(inputs)\n",
    "#     # Stage 2\n",
    "#     for idx in range(4):\n",
    "#         x = layers.Conv3D(32, (1,1,1), 1, activation='relu', name=f\"stage2_0_{idx}\")(x)\n",
    "#         x = layers.Conv3D(32, (1,3,3), 1, activation='relu', name=f\"stage2_1_{idx}\")(x)\n",
    "#         x = layers.Conv3D(128, (1,1,1), 1, activation='relu', name=f\"stage2_2_{idx}\")(x)\n",
    "#     # Stage 3\n",
    "#     for idx in range(6):\n",
    "#         x = layers.Conv3D(64, (3,1,1), 1, activation='relu', name=f\"stage3_0_{idx}\")(x)\n",
    "#         x = layers.Conv3D(64, (1,3,3), 1, activation='relu', name=f\"stage3_1_{idx}\")(x)\n",
    "#         x = layers.Conv3D(256, (1,1,1), 1, activation='relu', name=f\"stage3_2_{idx}\")(x)\n",
    "#     x = layers.AveragePooling3D()(x)\n",
    "#     for idx in range(3):\n",
    "#         x = layers.Conv3D(128, (3,1,1), 1, activation='relu', name=f\"stage4_0_{idx}\")(x)\n",
    "#         x = layers.Conv3D(128, (1,3,3), 1, activation='relu', name=f\"stage4_1_{idx}\")(x)\n",
    "#         x = layers.Conv3D(512, (1,1,1), 1, activation='relu', name=f\"stage4_2_{idx}\")(x)\n",
    "#     x = layers.AveragePooling3D()(x)\n",
    "#     x = layers.GlobalAveragePooling3D()(x)\n",
    "    \n",
    "#     outputs = layers.Dense(250, activation=\"softmax\")(x)\n",
    "#     return models.Model(inputs, outputs)\n",
    "\n",
    "def slowonly():\n",
    "    inputs = layers.Input(shape=(32,56,56,3))\n",
    "    # Stem\n",
    "    x = layers.Conv3D(32, (7,7,7), 1, activation='relu')(inputs)\n",
    "    # Stage 2\n",
    "    for idx in range(4):\n",
    "        x = layers.Conv3D(32, (1,1,1), 1, activation='relu', name=f\"stage2_0_{idx}\")(x)\n",
    "        x = layers.Conv3D(32, (1,3,3), 2, activation='relu', name=f\"stage2_1_{idx}\")(x)\n",
    "        x = layers.Conv3D(128, (1,1,1), 1, activation='relu', name=f\"stage2_2_{idx}\")(x)\n",
    "    x = layers.AveragePooling3D()(x)\n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    \n",
    "    outputs = layers.Dense(250, activation=\"softmax\")(x)\n",
    "    return models.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98987afb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 56, 56, 3)]   0         \n",
      "                                                                 \n",
      " conv3d (Conv3D)             (None, 26, 50, 50, 32)    32960     \n",
      "                                                                 \n",
      " stage2_0_0 (Conv3D)         (None, 26, 50, 50, 32)    1056      \n",
      "                                                                 \n",
      " stage2_1_0 (Conv3D)         (None, 13, 24, 24, 32)    9248      \n",
      "                                                                 \n",
      " stage2_2_0 (Conv3D)         (None, 13, 24, 24, 128)   4224      \n",
      "                                                                 \n",
      " stage2_0_1 (Conv3D)         (None, 13, 24, 24, 32)    4128      \n",
      "                                                                 \n",
      " stage2_1_1 (Conv3D)         (None, 7, 11, 11, 32)     9248      \n",
      "                                                                 \n",
      " stage2_2_1 (Conv3D)         (None, 7, 11, 11, 128)    4224      \n",
      "                                                                 \n",
      " stage2_0_2 (Conv3D)         (None, 7, 11, 11, 32)     4128      \n",
      "                                                                 \n",
      " stage2_1_2 (Conv3D)         (None, 4, 5, 5, 32)       9248      \n",
      "                                                                 \n",
      " stage2_2_2 (Conv3D)         (None, 4, 5, 5, 128)      4224      \n",
      "                                                                 \n",
      " stage2_0_3 (Conv3D)         (None, 4, 5, 5, 32)       4128      \n",
      "                                                                 \n",
      " stage2_1_3 (Conv3D)         (None, 2, 2, 2, 32)       9248      \n",
      "                                                                 \n",
      " stage2_2_3 (Conv3D)         (None, 2, 2, 2, 128)      4224      \n",
      "                                                                 \n",
      " average_pooling3d (AverageP  (None, 1, 1, 1, 128)     0         \n",
      " ooling3D)                                                       \n",
      "                                                                 \n",
      " global_average_pooling3d (G  (None, 128)              0         \n",
      " lobalAveragePooling3D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 250)               32250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 132,538\n",
      "Trainable params: 132,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = slowonly()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aeaea0a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 56, 56, 3)]   0         \n",
      "                                                                 \n",
      " conv3d (Conv3D)             (None, 26, 50, 50, 32)    32960     \n",
      "                                                                 \n",
      " stage2_0_0 (Conv3D)         (None, 26, 50, 50, 32)    1056      \n",
      "                                                                 \n",
      " stage2_1_0 (Conv3D)         (None, 13, 24, 24, 32)    9248      \n",
      "                                                                 \n",
      " stage2_2_0 (Conv3D)         (None, 13, 24, 24, 128)   4224      \n",
      "                                                                 \n",
      " stage2_0_1 (Conv3D)         (None, 13, 24, 24, 32)    4128      \n",
      "                                                                 \n",
      " stage2_1_1 (Conv3D)         (None, 7, 11, 11, 32)     9248      \n",
      "                                                                 \n",
      " stage2_2_1 (Conv3D)         (None, 7, 11, 11, 128)    4224      \n",
      "                                                                 \n",
      " stage2_0_2 (Conv3D)         (None, 7, 11, 11, 32)     4128      \n",
      "                                                                 \n",
      " stage2_1_2 (Conv3D)         (None, 4, 5, 5, 32)       9248      \n",
      "                                                                 \n",
      " stage2_2_2 (Conv3D)         (None, 4, 5, 5, 128)      4224      \n",
      "                                                                 \n",
      " stage2_0_3 (Conv3D)         (None, 4, 5, 5, 32)       4128      \n",
      "                                                                 \n",
      " stage2_1_3 (Conv3D)         (None, 2, 2, 2, 32)       9248      \n",
      "                                                                 \n",
      " stage2_2_3 (Conv3D)         (None, 2, 2, 2, 128)      4224      \n",
      "                                                                 \n",
      " average_pooling3d (AverageP  (None, 1, 1, 1, 128)     0         \n",
      " ooling3D)                                                       \n",
      "                                                                 \n",
      " global_average_pooling3d (G  (None, 128)              0         \n",
      " lobalAveragePooling3D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 250)               32250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 132,538\n",
      "Trainable params: 132,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# model = Resnet3DBuilder.build_resnet_34((32, 56, 56, 3), 250)\n",
    "model = slowonly()\n",
    "model.compile(\n",
    "    \"adam\",\n",
    "    \"categorical_crossentropy\",\n",
    "    metrics=[\"acc\"]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28954f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ayushthakur/asl/kaggle-asl/notebooks/wandb/run-20230418_232130-07xy81vx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ayush-thakur/kaggle-asl/runs/07xy81vx' target=\"_blank\">dry-planet-62</a></strong> to <a href='https://wandb.ai/ayush-thakur/kaggle-asl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ayush-thakur/kaggle-asl' target=\"_blank\">https://wandb.ai/ayush-thakur/kaggle-asl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ayush-thakur/kaggle-asl/runs/07xy81vx' target=\"_blank\">https://wandb.ai/ayush-thakur/kaggle-asl/runs/07xy81vx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project=\"kaggle-asl\",\n",
    "    job_type=\"train_poseconv3d\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a3d59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "      6/Unknown - 2s 72ms/step - loss: 5.5215 - acc: 0.0000e+00WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0266s vs `on_train_batch_end` time: 0.0428s). Check your callbacks.\n",
      "4675/4675 [==============================] - 370s 79ms/step - loss: 5.5229 - acc: 0.0027 - val_loss: 5.5204 - val_acc: 0.0043\n",
      "Epoch 2/10\n",
      "4675/4675 [==============================] - ETA: 0s - loss: 5.5224 - acc: 0.0033"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    trainloader,\n",
    "    epochs=10,\n",
    "    validation_data=validloader,\n",
    "    callbacks=[WandbMetricsLogger(log_freq=2)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30d28f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/acc</td><td>█▇▃▁▃▃▃▂▂▂▁▁▁▁▁▂▂▁▁▁▁▁▁▂▁▁▂▂▁▁▁▁▂▂▂▂▂▂▂▂</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>batch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/loss</td><td>▂▁▁▆▅▄▄▃▄▄▄▅▇███▇▇▇▆▆▅▅▅▄▄▄▄▅▅▆▇▇▆▆▆▆▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/acc</td><td>0.00334</td></tr><tr><td>batch/batch_step</td><td>560</td></tr><tr><td>batch/learning_rate</td><td>0.001</td></tr><tr><td>batch/loss</td><td>5.52292</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">upbeat-dream-61</strong> at: <a href='https://wandb.ai/ayush-thakur/kaggle-asl/runs/d21hkih5' target=\"_blank\">https://wandb.ai/ayush-thakur/kaggle-asl/runs/d21hkih5</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230418_231231-d21hkih5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9453b21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c8cdb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8124165e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7a1953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba88157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9387c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41de0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6d7254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bab817",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
