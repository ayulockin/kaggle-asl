{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84006d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n",
      "0.31.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import tensorflow_io as tfio\n",
    "print(tfio.__version__)\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "import tflite_runtime.interpreter as tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52028a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"../data/\"\n",
    "data_path = root_dir + \"train.csv\"\n",
    "model_path = \"../models/baseline-2Z27DBCM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3128316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "      <th>sign_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/train_landmark_files/26734/1000035562....</td>\n",
       "      <td>26734</td>\n",
       "      <td>1000035562</td>\n",
       "      <td>blow</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/train_landmark_files/28656/1000106739....</td>\n",
       "      <td>28656</td>\n",
       "      <td>1000106739</td>\n",
       "      <td>wait</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/train_landmark_files/16069/100015657.p...</td>\n",
       "      <td>16069</td>\n",
       "      <td>100015657</td>\n",
       "      <td>cloud</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/train_landmark_files/25571/1000210073....</td>\n",
       "      <td>25571</td>\n",
       "      <td>1000210073</td>\n",
       "      <td>bird</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/train_landmark_files/62590/1000240708....</td>\n",
       "      <td>62590</td>\n",
       "      <td>1000240708</td>\n",
       "      <td>owie</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  participant_id  \\\n",
       "0  ../data/train_landmark_files/26734/1000035562....           26734   \n",
       "1  ../data/train_landmark_files/28656/1000106739....           28656   \n",
       "2  ../data/train_landmark_files/16069/100015657.p...           16069   \n",
       "3  ../data/train_landmark_files/25571/1000210073....           25571   \n",
       "4  ../data/train_landmark_files/62590/1000240708....           62590   \n",
       "\n",
       "   sequence_id   sign  sign_encoded  \n",
       "0   1000035562   blow            25  \n",
       "1   1000106739   wait           232  \n",
       "2    100015657  cloud            48  \n",
       "3   1000210073   bird            23  \n",
       "4   1000240708   owie           164  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "\n",
    "def add_path(row):\n",
    "    return root_dir + row.path\n",
    "\n",
    "# Get labels 2 id\n",
    "with open(root_dir+\"sign_to_prediction_index_map.json\") as f:\n",
    "    label2id = json.load(f)\n",
    "\n",
    "df[\"path\"] = df.apply(lambda row: add_path(row), axis=1)\n",
    "df[\"sign_encoded\"] = df[\"sign\"].apply(lambda sign: label2id[sign])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "380adaad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 543, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROWS_PER_FRAME = 543  # number of landmarks per frame\n",
    "\n",
    "SAMPLE_FILE = train_df.path.values[100]\n",
    "\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)\n",
    "\n",
    "frames = load_relevant_data_subset(SAMPLE_FILE)\n",
    "frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebac1f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FRAMES = 32\n",
    "\n",
    "class DataPreprocessing(tf.Module):\n",
    "    def __init__(self, num_frames=NUM_FRAMES, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.num_frames = num_frames\n",
    "        \n",
    "    def true_fn(self, frames, n_frames):\n",
    "        num_left_frames = self.num_frames - n_frames\n",
    "        left_frames = tf.zeros(shape=(num_left_frames, 543, 3))\n",
    "        frames = tf.concat([frames, left_frames], 0)\n",
    "\n",
    "        return frames\n",
    "\n",
    "    def false_fn(self, frames):\n",
    "        frames = tf.slice(\n",
    "            frames,\n",
    "            begin=[0,0,0],\n",
    "            size=[self.num_frames, 543, 3]\n",
    "        )\n",
    "\n",
    "        return frames\n",
    "    \n",
    "    def shape_list(self, tensor):\n",
    "        \"\"\"\n",
    "        Deal with dynamic shape in tensorflow cleanly.\n",
    "        Args:\n",
    "            tensor (`tf.Tensor` or `np.ndarray`): The tensor we want the shape of.\n",
    "        Returns:\n",
    "            `List[int]`: The shape of the tensor as a list.\n",
    "        \"\"\"\n",
    "        if isinstance(tensor, np.ndarray):\n",
    "            return list(tensor.shape)\n",
    "\n",
    "        dynamic = tf.shape(tensor)\n",
    "\n",
    "        if tensor.shape == tf.TensorShape(None):\n",
    "            return dynamic\n",
    "\n",
    "        static = tensor.shape.as_list()\n",
    "\n",
    "        return [dynamic[i] if s is None else s for i, s in enumerate(static)]\n",
    "\n",
    "    def __call__(self, frames):\n",
    "        n_frames, _, _ = self.shape_list(frames)\n",
    "        \n",
    "        # nan to num\n",
    "        frames = tf.where(tf.math.is_nan(frames), 0.0, frames)\n",
    "\n",
    "        # sample frames\n",
    "        frames = tf.cond(\n",
    "            tf.less(n_frames, NUM_FRAMES),\n",
    "            true_fn = lambda: self.true_fn(frames, n_frames),\n",
    "            false_fn = lambda: self.false_fn(frames),\n",
    "        )\n",
    "\n",
    "        return tf.expand_dims(frames, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "caffcd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 543, 3)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 32, 468, 3)  0           ['input_1[0][0]']                \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " conv_lstm1d (ConvLSTM1D)       (None, 461, 32)      35968       ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 454, 32)      8224        ['conv_lstm1d[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 32, 21, 3)   0           ['input_1[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3 (Sl  (None, 32, 21, 3)   0           ['input_1[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2 (Sl  (None, 32, 33, 3)   0           ['input_1[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 227, 32)      0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_lstm1d_1 (ConvLSTM1D)     (None, 14, 32)       35968       ['tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv_lstm1d_2 (ConvLSTM1D)     (None, 14, 32)       35968       ['tf.__operators__.getitem_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv_lstm1d_3 (ConvLSTM1D)     (None, 26, 32)       35968       ['tf.__operators__.getitem_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 220, 64)      16448       ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 7, 64)        16448       ['conv_lstm1d_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 7, 64)        16448       ['conv_lstm1d_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 19, 64)       16448       ['conv_lstm1d_3[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 110, 64)     0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 3, 64)       0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 3, 64)       0           ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 9, 64)       0           ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 110, 64)      0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 3, 64)        0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 3, 64)        0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 9, 64)        0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 125, 64)      0           ['dropout[0][0]',                \n",
      "                                                                  'dropout_1[0][0]',              \n",
      "                                                                  'dropout_2[0][0]',              \n",
      "                                                                  'dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 8000)         0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 250)          2000250     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,218,138\n",
      "Trainable params: 2,218,138\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(model_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "171d3369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TFLiteModel(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    TensorFlow Lite model that takes input tensors and applies:\n",
    "        – a preprocessing model\n",
    "        – the ASL model \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, asl_model):\n",
    "        \"\"\"\n",
    "        Initializes the TFLiteModel with the specified feature generation model and main model.\n",
    "        \"\"\"\n",
    "        super(TFLiteModel, self).__init__()\n",
    "\n",
    "        # Load the feature generation and main models\n",
    "        self.prep_inputs = DataPreprocessing()\n",
    "        self.model = model\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, 543, 3], dtype=tf.float32, name='inputs')])\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Applies the feature generation model and main model to the input tensors.\n",
    "\n",
    "        Args:\n",
    "            inputs: Input tensor with shape [batch_size, 543, 3].\n",
    "\n",
    "        Returns:\n",
    "            A dictionary with a single key 'outputs' and corresponding output tensor.\n",
    "        \"\"\"\n",
    "        x = self.prep_inputs(tf.cast(inputs, dtype=tf.float32))\n",
    "        outputs = self.model(x)[0, :]\n",
    "\n",
    "        # Return a dictionary with the output tensor\n",
    "        return {'outputs': outputs}\n",
    "\n",
    "tflite_keras_model = TFLiteModel(model)\n",
    "demo_output = tflite_keras_model(load_relevant_data_subset(SAMPLE_FILE))[\"outputs\"]\n",
    "np.argmax(demo_output.numpy(), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b2b6994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5mvlpyty/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5mvlpyty/assets\n",
      "2023-03-10 16:20:25.682551: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-03-10 16:20:25.682606: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-03-10 16:20:25.683706: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmp5mvlpyty\n",
      "2023-03-10 16:20:25.729486: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-03-10 16:20:25.729528: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmp5mvlpyty\n",
      "2023-03-10 16:20:25.873534: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n",
      "2023-03-10 16:20:25.901817: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-03-10 16:20:26.126216: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmp5mvlpyty\n",
      "2023-03-10 16:20:26.301257: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 617559 microseconds.\n",
      "2023-03-10 16:20:26.933752: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-03-10 16:20:27.434663: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2111] Estimated count of arithmetic ops: 59.193 M  ops, equivalently 29.597 M  MACs\n"
     ]
    }
   ],
   "source": [
    "keras_model_converter = tf.lite.TFLiteConverter.from_keras_model(tflite_keras_model)\n",
    "tflite_model = keras_model_converter.convert()\n",
    "\n",
    "model_lite_path = \"../models/model.tflite\"\n",
    "\n",
    "with open(model_lite_path, 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44b73304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('serving_default', {'inputs': ['inputs'], 'outputs': ['outputs']})]\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "interpreter = tflite.Interpreter(model_lite_path)\n",
    "found_signatures = list(interpreter.get_signature_list().items())\n",
    "print(found_signatures)\n",
    "\n",
    "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "\n",
    "output = prediction_fn(inputs=load_relevant_data_subset(train_df.path[0]))\n",
    "sign = np.argmax(output[\"outputs\"])\n",
    "\n",
    "print(sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "218c6cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40000/40000 [57:53<00:00, 11.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 1min 55s, sys: 15min 58s, total: 2h 17min 53s\n",
      "Wall time: 57min 53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in tqdm(range(40000)):\n",
    "    output = prediction_fn(inputs=load_relevant_data_subset(train_df.path[i]))\n",
    "    sign = np.argmax(output[\"outputs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceaced9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfb0268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f650746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bea203c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e5bc25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ab1a61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb350450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29063bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daf946d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
